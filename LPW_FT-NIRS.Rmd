---
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: console
---
# FT-NIRS Otolith Age Prediction

This RMD serves as a guide/lab journal to document my methods for processing and modelling FT-NIRS otolith spectra from juvenile Pacific cod (__Gadus macrocephalus__) in the Gulf of Alaska.  These scans were acquired on a Bruker MPA II with an integrating sphere, 5mm. teflon disk taped over the scanning window and gold transflectance stamp placed over the top of samples.  Spectra were collected between 11,500 and 4,000 cm^-1^ with a resolution of 16 cm^-1^ and 64 replicate scans.

LPW Scans refer to specimens collected near Little Port Walter (LPW), a NOAA research station located near the southern tip of Baranof Island in Southeast Alaska.  Juvenile cod were collected using beach and purse seines from embayments near LPW on July 27-28, 2020. These fish were transferred into outdoor net pens at LPW to be reared in captivity.  Specimens were collected approximately weekly (ADD MORE IN HERE LATER)

## Load packages, import .0 files, create spectral dataframe
This segment is adapted from code provided by __Dr. Esther Goldstein__ at NOAA's AFSC in Seattle.  __(ADD INFO ON PACKAGES INCLUDED?)__

##### Load necessary packages
```{r, results = 'hide', warning = F, message = F, cache = T}
# Install packages not yet installed
packages <- c("dplyr", "tidyr", "EMSC", "purrr", "pls", "devtools", "hyperSpec", "prospectr", "data.table", "mdatools", "opusreader2", "splitstackshape", "ggplot2", "viridis", "mgcv", "caret", "MuMIn")
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  utils::install.packages(pkgs = packages[!installed_packages])
}
invisible(lapply(packages, library, character.only = TRUE)) # load all packages in list

# install packages not on CRAN
if (!require("remotes")) install.packages("remotes")
if (!require("opusreader2")) {
  remotes::install_github("spectral-cockpit/opusreader2")
  library("opusreader2")
}
if (!require("simplerspec")) {
  remotes::install_github("philipp-baumann/simplerspec")
  library("simplerspec")
}

rm(installed_packages) # remove objects from environment
rm(packages)
```

### Importing FT-NIRS Spectral Files (Opus .0) & Building Dataframe

The Bruker MPA outputs FT-NIRS spectra in a .0 format.  Prior to loading spectral data, a metadata .csv (`LPW_metadata.csv`) was generated to pair specimens biological data with their respective FT-NIRS scans.   

##### LPW Metadata Variables:

- Specimen # in dataset (`specimen`)
- Fish fork length (to nearest whole mm) (`length`)
- Fish whole body weight (to nearest whole gram), may have been taken when partially frozen  (`weight`)
- Weight of otolith (nearest 0.0001 gram) used for FT-NIRS scan (`structure_weight`)
- otolith read age (`read_age`) in days representing an average of multiple reads (agreement <= 5%)
- side of otolith scanned (`side`)
- % of otolith with some sort of abnormality including crystalization or broken/chipped portions (`percent_affected`)
- other problems include tissue stuck to otoliths (`other_problem`)
- whether an otolith was broken or chipped at all (`broken`)
- scan name/session or run number (`scan_name`, `run_number`) to indicate separate scans for the same specimen (LPW specimens scanned in triplicate)
- Filename of .0 opus files for each specimen & scan session (`file_name`)

### Grabbing filenames from .0 files for metadata .csv
To facilitate easier .0 file loading, all file names for .0 files should be added to the metadata file.  All filenames in a folder can be generated with list.files().  For pulling file names to create a new .csv, you can use:
```{r, results = 'hide', cache = T, collapse = T, eval = F, include = F}
cat(list.files(path = "LPW_scans/", ), "\n") # concatenates all filenames in a directory and adds a space delimiter
```
This output (without index numbers in square brackets) can be copied and pasted into Excel, then converted into columns using the "Data -> Text to Columns" function and selecting a "space" delimiter.  These columns can then be transposed into a `file_name` column.  

### Reading in FT-NIRS spectra from a Bruker MPA II
First I import my metadata (`LPW_metadata.csv`) and convert the `session_title` (i.e. scan #) to a factor.  LPW FT-NIRS scans were taken in triplicate (`NIR_LPW202001202_otoliths`, `...otoliths_rescan_1`, `...otoliths_rescan_2`) to see if spectra changed after storage.  Metadata for LPW contained an additional entry (`..._rescan_3`) with some notes and comments, however I will only be importing the metadata for actual scans.
```{r, cache = T}
meta_LPW <- read.csv("LPW_metadata.csv") # import metadata
levels(as.factor(as.character(meta_LPW$session_title))) # set session_title to factor (three scans taken at separate times).
meta_LPW <- meta_LPW[meta_LPW$session_title %in% c("NIR_LPW202001202_otoliths", "NIR_LPW202001202_otoliths_rescan_1", "NIR_LPW202001202_otoliths_rescan_2"), ] # only include scan sessions 1, 2 & 3
meta_LPW$specimen[meta_LPW$file_name == ""] # check for missing file_names in metadata

# the first scan of specimen 66 is missing and will be excluded for analysis.

meta_LPW <- meta_LPW[meta_LPW$file_name != "", ] # remove any rows that are missing a file_name in the metadata

# check number of specimens for each scan session (122 specimens, 365 total scans after excluding specimen 66, scan 1)
nrow(meta_LPW[meta_LPW$session_title %in% c("NIR_LPW202001202_otoliths"), ])
nrow(meta_LPW[meta_LPW$session_title %in% c("NIR_LPW202001202_otoliths_rescan_1"), ])
nrow(meta_LPW[meta_LPW$session_title %in% c("NIR_LPW202001202_otoliths_rescan_2"), ])

# generate file paths to import with Opusreader
setwd("LPW_scans/") # setwd to folder containing FT-NIRS scans
meta_LPW$file_path <- paste0(getwd(), "/", meta_LPW$file_name) # generate filepaths for all .0 files
Opusfiles <- as.vector(meta_LPW$file_path) # store filepaths in object
exists <- as.vector(lapply(Opusfiles, file.exists)) # check that I have all my files or else I get an error when I read them in
meta_LPW$exists <- exists # add column to metadata dataframe to confirm file exists in directory 
meta_LPW1 <- meta_LPW[meta_LPW$exists == "TRUE", ] # filter the file list and data by otoliths with spectra files
Opusfiles <- as.vector(meta_LPW1$file_path) # from Esther, "I repeated this and wrote over it so I wouldn't have extra files to read in that don't exist and produce an error"
rm(exists)
rm(meta_LPW1)
```
Once all metadata has been imported into a dataframe with filepaths for .0 files, FT-NIRS scans can be imported using the  `opusreader2` package and `read_opus()`.  First a single file is read-in to make sure the script works and everything looks good; then all .0 files are imported using the `Opusfiles` object.  `read_opus()` creates a massive list of lists that includes information about MPA II settings, metadata generated during scans, specimen names, etc.  See `?read_opus()` from the `opusreader2` package for more details on the list structure of .0 files.
```{r, cache = T, warning=FALSE}
# read a single file (one measurement) to check that script runs without failure
file <- Opusfiles[1]
data_list <- opusreader2::read_opus(dsn = file) # NA's seem to be introduced due to a timestamp metadata issue, currently using suppressWarnings to hide the annoying output, but this is normal.
rm(data_list)
rm(file)
SPCfiles_nooffset <- suppressWarnings(lapply(Opusfiles, opusreader2::read_opus)) # Read in all files in the Opusfiles list.  This gives an error if any file names or paths are wrong.
# uncomment to see additional output from .0 files

# str(SPCfiles_nooffset[[1]]) # check first element
# SPCfiles_nooffset[[1]][[1]]$ab$data # can see spc values this way I think
# SPCfiles_nooffset[[1]][[1]]$lab_and_process_param_raw$parameters #this has info about what setting was used (here otolith), species, and file name
SPCfiles_nooffset[[1]][[1]]$lab_and_process_param_raw$parameters$FC2$parameter_value # species
SPCfiles_nooffset[[1]][[1]]$lab_and_process_param_raw$parameters$FD1$parameter_value # unique ID, including project title (LPW2020), experimental designation (01 for experimental, mortalities are numbered 02), species code (202), specimen number (_1_) and scan number (OA1)
# SPCfiles_nooffset[[1]][[1]]$ab$wavenumbers # wavenumbers scanned
SPCfiles_nooffset[[1]][[1]]$instrument_ref$parameters$INS$parameter_value # instrument name
```
Once all .0 files with included metadata have been successfully read-in, FT-NIRS scan data can be extracted from the lists.
```{r, cache = T}
# extract absorbance measurements, wavenumbers scanned, unique specimen ID, species  & instrument name from .0 files list
spectra <- lapply(SPCfiles_nooffset, function(x) x[[1]]$ab$data) # FT-NIRS scan data, absorbance measurements at all 949 wavenumbers
wavenumber <- lapply(SPCfiles_nooffset, function(x) x[[1]]$ab$wavenumbers) # list of all wavenumbers scanned
file_id <- lapply(SPCfiles_nooffset, function(x) x$lab_and_process_param_raw$parameters$FD1$parameter_value) # unique ID in Opus
species <- lapply(SPCfiles_nooffset, function(x) x$lab_and_process_param_raw$parameters$FC2$parameter_value) # species
instrument <- lapply(SPCfiles_nooffset, function(x) x[[1]]$instrument_ref$parameters$INS$parameter_value) # instrument name
 # these could differ if settings changed or in light sources change

# create dataframe out of list
spectra <- lapply(spectra, as.data.frame) 
# add metadata to dataframe
for (i in 1:length(spectra)) {
  colnames(spectra[[i]]) <- wavenumber[[i]] # assign wavenumbers to columns of absorbance measurements
}
for (i in 1:length(spectra)) {
  spectra[[i]]$species <- species[[i]] 
}
for (i in 1:length(spectra)) {
  spectra[[i]]$file_id <- file_id[[i]]
}
for (i in 1:length(spectra)) {
  spectra[[i]]$instrument <- instrument[[i]]
}
for (i in 1:length(spectra)) {
  spectra[[i]]$file_path <- Opusfiles[[i]]
}

# extract file_name from file_path: test code on one file to 
try <- spectra[[1]] # specimen 1, scan session 1 
splitstackshape::cSplit(as.data.frame(try$file_path), sep = "/", splitCols = "try$file_path", type.convert = FALSE) %>% select(tail(names(.), 1))
rm(try)
# create file_name variable for all scans
file_name <- lapply(spectra, function(x) splitstackshape::cSplit(as.data.frame(x$file_path), sep = "/", splitCols = "x$file_path", type.convert = FALSE) %>% select(tail(names(.), 1)))
file_name[[1]][[1, 1]] # check that first element is correct
# add file_name variable to spectra dataframe
for (i in 1:length(spectra)) {
  spectra[[i]]$file_name <- file_name[[i]][[1, 1]]
}
rm(file_id, file_name, instrument, species, wavenumber, Opusfiles, i)
```
### Build final spectral dataframe for modelling and graphing
```{r, cache = T}
df <- as.data.frame(do.call(rbind, spectra)) # convert spectral list/dataframe to dataframe object
dfmeta_LPW <- dplyr::left_join(meta_LPW, df, by = c("file_name", "file_path")) # join metadata to spectral data
dfmeta_LPW <- dfmeta_LPW %>% select(-c("exists", "instrument")) # remove exists and instrument columns
rm(meta_LPW, df, spectra, SPCfiles_nooffset)
colnames(dfmeta_LPW) <- as.character(colnames(dfmeta_LPW)) # make sure column names are characters, not numeric
dfmeta_longLPW <- pivot_longer(dfmeta_LPW, cols = -c(1:20)) # pivot absorbance measurements to long format for easy plotting
dfmeta_longLPW <- dfmeta_longLPW %>% rename(., "wavenumber" = "name") # rename name column to wavenumber for clarification
dfmeta_longLPW$wavenumber <- as.numeric(as.character(dfmeta_longLPW$wavenumber)) # change class of wavenumber variable to a numeric

# Plot 7 specimens to see if data loaded properly.
ggplot() +
  geom_path(data = dfmeta_longLPW[dfmeta_longLPW$specimen %in% c(1, 10, 100, 101, 102, 103, 104), ], 
            aes(x = wavenumber, y = value, color = session_title, group = file_name), linewidth = .5) +
  scale_x_reverse() +
  labs(y = "Absorbance units", x = expression(paste("Wavenumber ", cm^-1))) +
  theme(
    axis.text = element_text(size = 10),
    axis.text.x =element_text(size=12,angle=25),
    axis.title = element_text(size = 12),
    legend.position = "none",
    strip.text = element_text(size = 14),
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 12),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black")
  ) +
  facet_wrap(~specimen)

# Save RDS for data transparency and easily enable others to work with dataframe without all these complicated import steps
# setwd("../")
# saveRDS(dfmeta_LPW, "RDS_dataframes/LPW_dfmeta.RDS")
# saveRDS(dfmeta_longLPW, "RDS_dataframes/LPW_dfmeta_long.RDS")
```
# LPW Data Exploration

#### Functions
Some functions useful for exploring data, including quick plotting PCA and seeing impact of different preprocessing filters
```{r, cache = T}
# ggplot function to plot spectra, colored by some factor
spec.fig <- function(mydf, color) { 
  #color <- as.character({{color}})
  ggplot(mydf) +
  geom_path(aes(x = name, y = value, color = {{ color }}, group = file_name)) +
  scale_x_reverse() +
  scale_color_viridis() + 
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1)))
  #theme(axis.text = element_text(size = 16),
    # axis.text.x = element_text(size = 12, angle = 25),
    # axis.title = element_text(size = 14),
    # legend.position = "right",
    # strip.text = element_text(size = 14),
    # legend.text = element_text(size = 14),
    # legend.title = element_text(size = 14),
    # panel.grid.major = element_blank(),
    # panel.grid.minor = element_blank(),
    # panel.background = element_blank(),
    # axis.line = element_line(colour = "black")
  #)
}
# spec.fig(scan_avg_long,length)

# function to plot results of different savitzkyGolay filter params
sg_plotting <- function(color, m, p, w) { 
  dftempproc <- as.data.frame(
    cbind(scan_avg[, c(1:20)],
          savitzkyGolay(scan_avg[,21:length(scan_avg)],
                        m = m, p = p, w = w)
  ))
  dftempproc_long <- tidyr::pivot_longer(dftempproc, cols = c(21:length(dftempproc)))
  dftempproc_long$name <- as.numeric(as.character(dftempproc_long$name))
  spec.fig(mydf = dftempproc_long, color = {{ color }}) + 
    ggtitle(paste("diff = ", {{ m }}, "poly = ", {{ p}}, "window = ", {{ w }}))
}
# sg_plotting(specimen,1,3,17)
# sg_plotting(specimen,1,2,17)

# function to apply savitzkyGolay filter with selected parameters to dataframe and create new temp_proc and temp_proc_long dataframes for modelling
quickproc <- function(df, m, p, w){
  temp_proc <<- as.data.frame(
    cbind({{df}}[, c(1:20)],
          savitzkyGolay({{df}}[,21:length({{df}})],
                        m = m, p = p, w = w)
  ))
  temp_proc_long <<- tidyr::pivot_longer(temp_proc, cols = c(21:length(temp_proc)))
  temp_proc_long$name <<- as.numeric(as.character(temp_proc_long$name))
}
```

#### PCA on 3 scans
Preliminary spectra and PCA plots were explored to see whether spectra of different scans were similar enough to warrant combining for analyses.  Previous research has shown FT-NIRS spectra can change quite a bit over time and the triplicate scans of LPW otoliths were collected over nearly a year between the first and third scans.
```{r, cache = T}
# set run_number as factor for color groupings in plots
dfmeta_longLPW$run_number <- as.factor(dfmeta_longLPW$run_number)
dfmeta_LPW$run_number <- as.factor(dfmeta_LPW$run_number)
# Plot FT-NIRS scans, all 3 runs, colored by run_number
ggplot(dfmeta_longLPW) + geom_path(aes(x = wavenumber, y = value, 
                                       color = run_number, group = file_name),alpha = 0.5) + 
  labs(y = "Absorbance units", x = expression(paste("Wavenumber ", cm^-1)), color = "Run Number") +
  scale_color_viridis(discrete = T) + 
  scale_x_reverse() + # FT-NIRS spectra often displayed with reversed x-axis for otoliths - lower wavenumbers generally more informative and are more easily seen away from axes
  ggtitle("LPW FT-NIRS Spectra, All Scan Sessions")
# appear to be slightly different  values for each scan, look at 1 & 2 first
ggplot(dfmeta_longLPW[dfmeta_longLPW$run_number %in% c(1,2),]) + geom_path(aes(x = wavenumber, y = value, color = run_number, group = file_name)) + 
  labs(y = "Absorbance units", x = expression(paste("Wavenumber ", cm^-1)), color = "Run Number") +
  scale_color_viridis(discrete = T) + 
  scale_x_reverse() + 
  ggtitle("LPW FT-NIRS Spectra, Scans 1 & 2")
# Scans 1 & 3
ggplot(dfmeta_longLPW[dfmeta_longLPW$run_number %in% c(1,3),]) + geom_path(aes(x = wavenumber, y = value, color = run_number, group = file_name)) + 
  labs(y = "Absorbance units", x = expression(paste("Wavenumber ", cm^-1)), color = "Run Number") +
  scale_color_viridis(discrete = T) + 
  scale_x_reverse() + 
  ggtitle("LPW FT-NIRS Spectra, Scans 1 & 3")
# Scans 2 & 3
ggplot(dfmeta_longLPW[dfmeta_longLPW$run_number %in% c(2,3),]) + geom_path(aes(x = wavenumber, y = value, color = run_number, group = file_name)) + 
  labs(y = "Absorbance units", x = expression(paste("Wavenumber ", cm^-1)), color = "Run Number") +
  scale_color_viridis(discrete = T) + 
  scale_x_reverse() + 
  ggtitle("LPW FT-NIRS Spectra, Scans 2 & 3")
# Scan 1 looks quite different than 2 & 3.  These should be triplicate scans with identical values for each of the 122 specimens.  To confirm, I extract/plot the first 2 principal components for all FT-NIRS wavenumbers (indices 21:ncol(dfmeta_LPW)) and color points by run number.
pca_all_LPW <- pca(dfmeta_LPW[21:ncol(dfmeta_LPW)], scale = T)
pcs <- as.data.frame(cbind(pc2 = pca_all_LPW$calres$scores[,2], run_number = dfmeta_LPW$run_number)) # extract scores for PC2
pcs <- cbind(pc1 = pca_all_LPW$calres$scores[,1], pcs) # extract scores for PC1

# plot PC1 & PC2, colored by run_number
ggplot(pcs) + 
  geom_point(aes(x = pc1, y = pc2, color = as.factor(run_number)), size = 3) + 
  labs(x = paste("PC1 (", 
                 round(pca_all_LPW$calres$expvar[1], digits = 3),# variance explained by PC1
                 "% var. explained )"),
       y = paste("PC2 (", 
                 round(pca_all_LPW$calres$expvar[2], digits = 3), # variance explained by PC2
                 "% var. explained )"),
       color = "Run Number") +
  scale_color_viridis(discrete = T)
# run/scan #1 confirmed to be quite different.  Something appears to have changed between scan periods, however it is unknown exactly what occurred.  All future analysis will combine absorbance measurements from scans 2 & 3 and average.  
rm(pca_all_LPW,pcs)
```

#### Combining/averaging LPW FT-NRIS scans 2 & 3, preprocessing & filtering spectra >7500 cm-1

Combining scans 2 & 3 into a single average scan. Scan 1 is being ignored due to PCA above  

Spectral preprocessing serves to remove unwanted noise from absorbance measurements, filter out NIR backscatter, and can  improve model fits by increasing variability of absorbance measurements at wavenumbers between specimens.  Initial preprocessing done with prospectr and a savitzkygolay filter.  Will stick with one method and explore others later if time allows.

Removing noisy stretch of spectra > 7500 cm-1 - similar approach done by Matta et al. in Walleye Pollock daily age paper and seems typical for otolith FT-NIRS work.  

```{r, cache = T}
scan_2 <- dfmeta_LPW %>% dplyr::filter(run_number == 2)
# scan_2_long <- pivot_longer(scan_2, cols = `11536`:`3952`, names_to = "name", values_to = "value")
# scan_2_long$name <- as.numeric(scan_2_long$name)
scan_3 <- dfmeta_LPW %>% dplyr::filter(run_number == 3)
# scan_3_long <- pivot_longer(scan_3, cols = `11536`:`3952`, names_to = "name", values_to = "value")
# scan_3_long$name <- as.numeric(scan_3_long$name)
scan_avg <- bind_cols(NULL, scan_2[, 1:20])
scan_avg <- bind_cols(scan_avg, (scan_2[, 21:ncol(scan_2)] + scan_3[, 21:ncol(scan_3)]) / 2)
rm(scan_2, scan_3)

# preprocess immediately right now
scan_avg <- cbind(scan_avg[, c(1:20)], 
                  savitzkyGolay(scan_avg[,21:length(scan_avg)],m = 1, p = 3, w = 17))
scan_avg_long <- pivot_longer(scan_avg, cols = `11472`:`4016`, names_to = "name", values_to = "value")
scan_avg_long$name <- as.numeric(scan_avg_long$name)





#### Testing for now ####

# removing the noisy stretch of spectra (>7500, up to 7504)
scan_avg_filter <- scan_avg[,-c(21:517)]
scan_avg_filter_long <- pivot_longer(scan_avg_filter, cols = `7496`:`4016`, names_to = "name", values_to = "value")
scan_avg_filter_long$name <- as.numeric(scan_avg_filter_long$name)

# Saving RDS files

# saveRDS(scan_avg, "RDS_dataframes/LPW_scan_avg.RDS")
# saveRDS(scan_avg_long, "RDS_dataframes/LPW_scan_avg_long.RDS")
# saveRDS(scan_avg_filter, "RDS_dataframes/LPW_scan_avg_filter.RDS")
# saveRDS(scan_avg_filter_long, "RDS_dataframes/LPW_scan_avg_filter_long.RDS")
```

# Read Dataframes

```{r}
# dfmeta_LPW <- readRDS("RDS_dataframes/LPW_dfmeta.RDS")
# dfmeta_longLPW <- readRDS("RDS_dataframes/LPW_dfmeta_long.RDS")
# scan_avg <- readRDS("RDS_dataframes/LPW_scan_avg.RDS")
# scan_avg_long <- readRDS("RDS_dataframes/LPW_scan_avg_long.RDS")
# scan_avg_filter <- readRDS("RDS_dataframes/LPW_scan_avg_filter.RDS")
# age_only <- readRDS("RDS_dataframes/LPW_age_only.RDS")


# test_pls_length <- readRDS("RDS_dataframes/PLS_Length")
# test_pls_length_VIP <- readRDS("RDS_dataframes/PLS_Length_VIP")
# test_pls_length_unproc <- readRDS("RDS_dataframes/PLS_Length_unproc")
# test_pls_length_split <- readRDS("RDS_dataframes/PLS_Length_split")
# test_pls_length_split_VIP <- readRDS("RDS_dataframes/PLS_Length_split_VIP")
```

# Modelling with PCs - lm() & non-linear gam()

```{r}
# Create dataframe only with ages contained in metadata
age_only <- scan_avg_filter[complete.cases(scan_avg_filter$read_age), ]

# outliers identified with plotly and PCA, colored by age.  
age_only <- age_only %>%
  dplyr::filter(read_age != 175, read_age != 135, read_age != 146, specimen != 65, read_age != 147, read_age != 181, read_age != 161, read_age != 188)
# saveRDS(age_only, "RDS_dataframes/LPW_age_only.RDS")

# 10 fold CV split - create folds
set.seed(6)
splits <- caret::createFolds(age_only$read_age, k = 10, list = TRUE, returnTrain = FALSE)

# extract PC's for each calibration set, create test sets with ages and spectra
cal <- list()
test <- list()
for (i in 1:10) {
  # calibration set and PC's
  pc.mod <- preProcess(age_only[-splits[[i]], -c(1:20)], method = "pca", thresh = 0.95, pcaComp = 4)
  pc.cal <- predict(pc.mod, age_only[-splits[[i]], -c(1:20)])
  pc.cal <- cbind(pc.cal, age_only[-splits[[i]], ])
  cal[[i]] <- pc.cal
  # test sets
  pc.test <- predict(pc.mod, age_only[splits[[i]], -c(1:20)])
  pc.test <- cbind(pc.test, age_only[splits[[i]], ])
  test[[i]] <- pc.test
}

# store metrics from each fold and each model type
RMSE.age <- list()
r2.age <- list()
AIC.age <- list()
AICc.age <- list()

# determine which PC's to include via step & AIC selection
mod.sel <- list()
for (i in 1:10) {
  pctest <- cal[[i]]
  temp <- step(lm(data = pctest[-splits[[i]], ], read_age ~ PC1 + PC2 + PC3 + PC4))
  mod.sel[[i]] <- rownames(summary(temp)$coef)
}
table(unlist(mod.sel))
# PC 2 seems uninformative, will leave out of lm(), GAM with select = T can choose to ignore it if need be

# lm() with 10-fold CV
lm.mods <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- lm(data = calibrate, read_age ~ PC1 + PC3 + PC4)
  RMSE.age$lm.cal[i] <- caret::RMSE(pred = mod$fitted.values, obs = calibrate[, 15])
  preds <- predict(mod, newdata = testing)
  RMSE.age$lm.test[i] <- caret::RMSE(pred = preds, obs = testing[, 15])
  r2.age$lm.cal[i] <- summary(mod)$r.squared
  RSS <- sum((testing$read_age - preds)^2)
  TSS <- sum((testing$read_age - mean(testing$read_age))^2)
  r2.age$lm.test[i] <- 1 - (RSS / TSS)
  AIC.age$lm[i] <- AIC(mod)
  AICc.age$lm[i] <- AICc(mod)
  lm.mods[[i]] <- mod
}
RMSE.age$lm.cal <- mean(RMSE.age$lm.cal)
RMSE.age$lm.test <- mean(RMSE.age$lm.test)
r2.age$lm.cal <- mean(r2.age$lm.cal)
r2.age$lm.test <- mean(r2.age$lm.test)

# GAM with 10 fold CV, select = T allows PCs to be penalized and effectively removed from model if appropriate. 
GAM.mods <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- gam(data = calibrate, read_age ~ s(PC1) + s(PC2) + s(PC3) + s(PC4), method = "ML", select = T)
  # Extract AIC, AICc, RMSE (cal & test) & r2 (cal & test)
  RMSE.age$GAM.cal[i] <- caret::RMSE(pred = mod$fitted.values, obs = calibrate[, 15])
  preds <- predict(mod, newdata = testing)
  RMSE.age$GAM.test[i] <- caret::RMSE(pred = preds, obs = testing[, 15])
  r2.age$gam.cal[i] <- summary(mod)$r.sq
  RSS <- sum((testing$read_age - preds)^2)
  TSS <- sum((testing$read_age - mean(testing$read_age))^2)
  r2.age$gam.test[i] <- 1 - (RSS / TSS)
  AIC.age$gam[i] <- AIC(mod)
  AICc.age$gam[i] <- AICc(mod)
  GAM.mods[[i]] <- mod
}
r2.age$gam.cal <- mean(r2.age$gam.cal)
r2.age$gam.test <- mean(r2.age$gam.test)
RMSE.age$GAM.cal <- mean(RMSE.age$GAM.cal)
RMSE.age$GAM.test <- mean(RMSE.age$GAM.test)


##### PLS COMPARISON - INCOMPLETE

# potentially use plsdof package to compute AIC??

pls.mods <- list()
# test pls, no variable selection
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- pls(calibrate[, 25:ncol(calibrate)], calibrate[, 15],
    scale = F, center = T,
    info = "Age Prediction Model", cv = 1,
    x.test = testing[, 25:ncol(testing)], y.test = testing[, 15]
  )
  RMSE.age$pls.cal[i] <- mod$calres$rmse[[3]]
  RMSE.age$pls.test[i] <- mod$testres$rmse[[3]]
  r2.age$pls.cal[i] <- mod$calres$r2[[3]]
  r2.age$pls.test[i] <- mod$testres$r2[[3]]
  # I don't think this is appropriate for calculating AIC and in fact AIC shouldn't be used for PLS?
  # RSS <- sum((mod$calres$y.ref - mod$calres$y.pred[,3,])^2)
  # n <- length(mod$calres$y.ref)
  # AIC.age$pls[i] <- n * log(RSS/n) + (2 * mod$ncomp.selected)
  pls.mods[[i]] <- mod
}
RMSE.age$pls.cal <- mean(RMSE.age$pls.cal)
RMSE.age$pls.test <- mean(RMSE.age$pls.test)
r2.age$pls.cal <- mean(r2.age$pls.cal)
r2.age$pls.test <- mean(r2.age$pls.test)

# temp <- list()
# for(i in 1:10){
# temp[[i]] <- pls.mods[[i]]$ncomp.selected
# }
# table(unlist(temp))

# library(plsdof)
# 
# pls.ic(RSS,dof)
# RSS <- sqrt(pls.mods[[5]]$calres$rmse * 1 /nrow(pls.mods[[5]]$calres$y.pred)) 
# RSS <- as.vector(RSS[1:20])
# sigmahat <- x
# 
# 
# regcoeffs.getStats(coef(pls.mods[[5]]))

pls.mods[[5]]$limParams
dof <- as.vector(pls.mods[[5]]$limParams$T2$moments$Nu[1:20])
summary(pls.mods[[5]]$coeffs)
pls.mods[[5]]$calres$sep
plotDistDoF(pls.mods[[5]])
show(getRegcoeffs(pls.mods[[5]],2))


my.pls2<-pls.ic(pls.mods[[5]]$calres$y.ref,pls.mods[[5]]$calres$y.pred,criterion="bic")
X<-as.matrix(Boston[,-14])
y<-as.vector(Boston[,14])

dof <

mod.summary <- data.frame(
  model = c("lm_cal", "lm_test", "gam_cal", "gam_test", "pls_cal", "pls_test"),
  r2 = 1:6,
  RMSE = 1:6
)
mod.summary$r2 <- unlist(r2.age)
mod.summary$RMSE <- unlist(RMSE.age)

# AIC.age$lm <- mean(AIC.age$lm)
# AIC.age$gam <- mean(AIC.age$gam)
# AIC.age$pls <- mean(AIC.age$pls)
AIC.summary <- data.frame(
  model = c(rep("lm", 10), rep("gam", 10)),
  AIC = 1:20,
  AICc = 1:20
)
# AIC.age <- AIC.age[-3]
AIC.summary$AIC <- unlist(AIC.age)
AIC.summary$AICc <- unlist(AICc.age)

```

# Plotting model results

```{r}
# corrplots to show what the data look like and show how highly correlated they are

library(corrplot)
temp <- as.data.frame(matrix(nrow = 10, ncol = 50))
for (i in 1:50) {
  temp[, i] <- rnorm(10)
}
# corrplot::corrplot(cor(age_only[,100:150]), tl.cex = 0.1)
corrplot::corrplot(cor(age_only[, 100:150]), tl.pos = "n", method = "color", cl.cex = 2)
# corrplot::corrplot(cor(temp), tl.cex = 0.1)
corrplot::corrplot(cor(temp), tl.cex = 0.1, , tl.pos = "n", method = "color", cl.cex = 2)

# show the FT-NIRS data
library(ggthemes)
scan_avg_filter_long <- pivot_longer(scan_avg, cols = `7496`:`4016`, names_to = "name", values_to = "value")
scan_avg_filter_long$name <- as.numeric(scan_avg_filter_long$name)
age_only_long <- scan_avg_filter_long[complete.cases(scan_avg_filter_long$read_age), ]
age_only_long <- age_only_long %>% dplyr:::filter(read_age != 175, read_age != 135, read_age != 146, specimen != 65, read_age != 147, read_age != 181, read_age != 161, read_age != 188)

# single specimen scan

plot1 <- age_only_long %>%
  dplyr::filter(specimen == 2) %>%
  ggplot() +
  theme_stata() +
  geom_path(aes(x = name, y = value, group = as.factor(file_name)),, size = 2) +
  scale_x_reverse() +
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1))) +
  theme(
    axis.title = element_text(size = 25),
    axis.text = element_text(size = 20)
  )
plot1

# 20 specimen scans

plot2 <- age_only_long %>%
  dplyr::filter(specimen %in% c(1:20)) %>%
  ggplot() +
  geom_path(aes(x = name, y = value, color = specimen, group = as.factor(file_name)), size = 2) +
  scale_x_reverse() +
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1))) +
  theme_stata() + 
  theme(
    axis.title = element_text(size = 25),
    axis.text = element_text(size = 20),
    legend.position = "none"
  )
plot2

# all specimens with ages (excluding outliers)

plot3 <- ggplot(age_only_long) +
  geom_path(aes(x = name, y = value, color = read_age, group = as.factor(file_name)), size = 1.1) +
  scale_x_reverse() +
  scale_color_viridis(option = "viridis") +
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1))) +
  theme_stata() +
  theme(
    axis.title = element_text(size = 25),
    axis.text = element_text(size = 20),
    legend.position = c(0.39, 0.66)
  ) +
  labs(colour = "Age (days)")

plot3 + theme(legend.text = element_text(size = 25, vjust = .2),
    legend.title = element_text(size = 30, vjust = 1)) + 
  guides(color = guide_colorbar(barheight = 9, barwidth = 2.5))

# plots of model performance

actual <- list()
pred_lm <- list()
pred_gam <- list()

# create dataframe with predictions vs actual age
for(i in 1:10){
  actual[[i]] <- test[[i]]$read_age
  pred_lm[[i]] <- predict(lm.mods[[i]],test[[i]])
  pred_gam[[i]] <- predict(GAM.mods[[i]],test[[i]])
}
predictions <- data.frame(actual = rep(0,53),
                          pred_lm = rep(0,53),
                          pred_gam = rep(0,53))
predictions$actual <- unlist(actual)
predictions$pred_lm <- unlist(pred_lm)
predictions$pred_gam <- unlist(pred_gam)
rm(actual, pred_lm,pred_gam)

ggplot(data = predictions) + 
  geom_point(aes(x = actual, y = pred_lm), color = "red") + 
  geom_point(aes(x = actual, y = pred_gam), color = "blue") + 
  geom_abline(slope = 1) + 
  xlab("Age (days)") + 
  ylab("Predicted age (days)")

# LM model performance

r2lmlab <- expression(paste(r^2, " = ", 0.7836))
rmselmlab <- paste("RMSE = ", round(RMSE.age$lm.test,3))

plot4 <- ggplot() + 
  theme_stata() + 
  geom_point(data = predictions,aes(x = actual, y = pred_lm), color = "red", size = 8) +
  geom_abline(slope = 1, size = 2.5) + 
  xlab("Age (days)") + 
  ylab("Predicted age (days)") +
  geom_text(aes(x = 183, y = 130), size = 13,label = r2lmlab) +
  geom_text(aes(x = 180, y = 124), size = 13, label = rmselmlab) + 
  theme(axis.title = element_text(size = 30),
    axis.text = element_text(size = 25))
plot4 


# GAM model performance

r2gamlab <- expression(paste(r^2, " = ", 0.7886))
rmsegamlab <- paste("RMSE = ", round(RMSE.age$GAM.test,3))

plot5 <- ggplot() + 
    theme_stata() + 
  geom_point(data = predictions,aes(x = actual, y = pred_gam), color = "blue", size = 8) +
  geom_abline(slope = 1, size = 2.5) + 
  xlab("Age (days)") + 
  ylab("Predicted age (days)") +
  geom_text(aes(x = 183, y = 125),size = 13,label = r2gamlab) +
  geom_text(aes(x = 180, y = 119),size = 13,label = rmsegamlab) + 
  theme(axis.title = element_text(size = 30),
    axis.text = element_text(size = 25))
plot5


###### OTHER PLOTTING CODE ######


# USEFUL PACKAGES!!!!
# visreg, gratia, gridExtra, gglm, 
library(gridExtra)
library(visreg)
library(gratia)
library(gglm)

# Using test/cal split # 5 for model performance

# GAM model performance


# GAM diagnostics
appraise(GAM.mods[[5]]) & theme_stata() & 
  theme(plot.title = element_text(size = 22), axis.title = element_text(size = 20),axis.text = element_text(size = 18))

# GAM partial effects
draw(GAM.mods[[5]],residuals = T) & theme_stata() & 
  theme(plot.title = element_text(size = 22), axis.title = element_text(size = 20),axis.text = element_text(size = 18))

# ggplot version of lm diagnostics
gglm(lm.mods[[5]], theme = theme_stata(), theme(plot.title = element_text(size = 22), axis.title = element_text(size = 20),axis.text = element_text(size = 18)) )
     
# grid.arrange(plot1,plot2,
#              plot3,plot4)
```