---
output: html_document
editor_options: 
  chunk_output_type: console
---


# All old code no longer being used - archiving to see where mistakes were made...!

# Variable/Wavelength Selection & PLS on __length__ as a test
Using temp_proc df produced from quickproc() function above.  VIP score to select wavelengths that are most informative to model

```{r}
quickproc(scan_avg,1,3,17) # SG of scan_avg DF to genereate temp_proc df for models below

test_pls_length <- pls(temp_proc[, 21:ncol(temp_proc)], temp_proc[, 2],
  scale = T, center = F, info = "Length Prediction Model",
  cv = 1
)
saveRDS(test_pls_length, "RDS_dataframes/PLS_Length")

# pls only with wavenumebrs VIP > 1
length_VIP <- vipscores(test_pls_length) # extract VIP values for wavenumbers of above pls model
plotVIPScores(test_pls_length)
test_waves <- names(subset(length_VIP[,1], length_VIP[,1] > 1)) 
all_waves <- names(temp_proc[,21:length(temp_proc)])
bad_waves <- all_waves[!(all_waves %in% test_waves)]
test_pls_length_VIP <- pls(temp_proc[,21:ncol(temp_proc)], temp_proc[,2],
  scale = T, center = F, info = "Length Prediction Model",
  exclcols = bad_waves,
  cv = 1
)
saveRDS(test_pls_length_VIP, "RDS_dataframes/PLS_Length_VIP")

# unprocessed df PLS
test_pls_length_unproc <- pls(scan_avg[, 21:ncol(scan_avg)], scan_avg[, 2],
  scale = T, center = F, info = "Length Prediction Model",
  cv = 1
)
saveRDS(test_pls_length_unproc, "RDS_dataframes/PLS_Length_unproc")

# 90% train, 10% test PLS, no VIP
set.seed(1)
idx <- floor(nrow(temp_proc) * 0.9)
train_idx <- sample(seq_len(nrow(temp_proc)), size = idx)
train <- temp_proc[train_idx, -c(1,3:20)]
test <- temp_proc[-train_idx, -c(1,3:20)]
test_pls_length_split <- pls(train[,-c(1)], train[,1],
  scale = T, center = F,
  info = "Length Prediction Model", cv = 1,
  x.test = test[,-c(1)], y.test = test[,1]
)
saveRDS(test_pls_length_split, "RDS_dataframes/PLS_Length_split")

# 90% train, 10% test PLS, VIP
test_pls_length_split_VIP <- pls(train[,-c(1)], train[,1],
  scale = T, center = F,
  info = "Length Prediction Model", cv = 1,
  x.test = test[,-c(1)], y.test = test[,1],
  exclcols = bad_waves
)
saveRDS(test_pls_length_split_VIP, "RDS_dataframes/PLS_Length_split_VIP")

plot(test_pls_length)
plot(test_pls_length_VIP)
plot(test_pls_length_unproc)
plot(test_pls_length_split)
plot(test_pls_length_split_VIP)

test_pls_length$res$cal$rmse[2]
test_pls_length_VIP$res$cal$rmse[3]
test_pls_length_unproc$res$cal$rmse[3]
test_pls_length_split$res$test$rmse[2]
test_pls_length_split_VIP$res$test$rmse[3]

rm(test_pls_length, test_pls_length_VIP, test_pls_length_unproc, test_pls_length_split, test_pls_length_split_VIP)
rm(test,train,length_VIP, all_waves, bad_waves, idx, test_waves, train_idx)
```



# PCR for age

```{r}
quickproc(age_only,1,3,17)
pca_age_LPW <- pca(temp_proc[21:ncol(temp_proc)], scale = T)
plot(pca_age_LPW)
mlr_age_pcs <- pca_age_LPW$calres$scores[,1:10]
mlr_age_pcs <- cbind(mlr_age_pcs, temp_proc[,1:11])
mlr_age <- lm(data = mlr_age_pcs, read_age ~ `Comp 1` + `Comp 2` + `Comp 3` + `Comp 4` + `Comp 5`)
summary(mlr_age)

# MLR with split
set.seed(1)
idx <- floor(nrow(age_only) * 0.9) # 90% of indices needed for training set
train_idx <- sample(seq_len(nrow(age_only)), size = idx) # generate indices for training set
train <- mlr_age_pcs[train_idx, -c(11:20)] # wavenumber measurement columns only
test <- mlr_age_pcs[-train_idx, -c(11:20)]
mlr_age_split <- lm(data = train, read_age ~`Comp 1` + `Comp 2` + `Comp 3` + `Comp 4` + `Comp 5`)
summary(mlr_age_split)
mlr_age_split_pred <- predict(mlr_age_split,test)
ggplot() +  # fitted values vs actual, out of sample prediction in red
  geom_point(aes(train$read_age,mlr_age_split$fitted.values)) + 
  geom_point(aes(test$read_age,mlr_age_split_pred),col = "red") + 
  geom_abline(slope=1, intercept = 0, col = "red")

# Split for PCR
set.seed(1)
idx <- floor(nrow(temp_proc) * 0.9)
train_idx <- sample(seq_len(nrow(temp_proc)), size = idx)
train <- age_only[train_idx, -c(1:10,12:20)] 
test <- age_only[-train_idx, -c(1:10,12:20)] 

pcr_age_model <- pcr(read_age ~ .,
                 data = train, 
                 scale = T,
                 validation = "CV",
                 ncomp = 10)
selectNcomp(pcr_age_model, "onesigma", plot = TRUE) # determine appropriate number of comps
scoreplot(pcr_age_model) # plot of first 2 PCs

pcr_age_pred <- predict(pcr_age_model, newdata = test, ncomp = 4) # fit model to test data, store fitted values
ggplot() +
  geom_point(aes(x = train$read_age, y = pcr_age_model$fitted.values[, , 4])) + # extract fitted values of model with 2 PCs.
  geom_point(aes(x = test$read_age, y = pcr_age_pred), col = "red") +
  geom_abline(slope = 1, col = "red")

RMSEP(pcr_age_model)


```


# PCR & PC GAMs using length

This code is no longer relevant; I was incorrectly applying the PCA prior to splitting dataset.
```{r}

# extract PC's
pca_LPW <- pca(scan_avg[21:ncol(scan_avg)], scale = T) # PCA for scan_avg
plot(pca_LPW)
pca_LPW <- pca_LPW$calres$scores[, 1:20] # extract PCs
pca_LPW <- cbind(pca_LPW[, 1:10], scan_avg[, 1:20]) # only store first 10 PC's
colnames(pca_LPW)[c(1:10)] <- c("PC1", "PC2", "PC3", "PC4", "PC5","PC6", "PC7", "PC8", "PC9", "PC10")

# PCR
PCR_length <- lm(data = pca_LPW, length ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
summary(PCR_length) # some PC's seem less informative than others
PCR_length2 <- update(PCR_length, length ~ PC1 + PC2 + PC5 + PC6 + PC8 + PC10)
summary(PCR_length2)
plot(PCR_length)
plot(PCR_length2)


PCR_length3 <- pcr(length ~ ., data = scan_avg[,c(2,21:ncol(scan_avg))], ncomp = 20,
                   validation = "CV")
selectNcomp(PCR_length3, "onesigma", plot = TRUE) # determine appropriate number of comps, suggested 4
scoreplot(PCR_length3) # plot of first 2 PCs


PCR_length3$fitted.values[,,4]


set.seed(1)
inTraining <- createDataPartition(scan_avg$length, p = .9, list = F)
training <- scan_avg[inTraining,-c(1,3:20)]
testing  <- scan_avg[-inTraining,-c(1,3:20)]
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10,
                           preProcOptions = list(pcaComp = 10))
PCR_length4 <- train(length ~ ., data = training, 
                 method = "lm", 
                 trControl = fitControl,
                 preProcess = "pca")
PCR_length4$
scan_avg[inTraining,-c(1,3:20)]

pca <- prcomp(scan_avg[inTraining,-c(1:20)],center=F,scale=T)
pca$rotation
pca$sdev
pca_LPW$PC1
dim(pca_LPW1$x)
pca_LPW1$loadings
testing1 <- preProcess(scan_avg[inTraining,-c(1:20)], method = "pca", pcaComp = 10)
predict(testing1, scan_avg[inTraining,-c(1,3:ncol(scan_a))])


postResampleSpectro(predict(PCR_length4,testing),testing$length)
PCR_length4
pcr1
PCR_length4$finalModel






# PCR with 10-fold split for RMSE
set.seed(1)
splits <- caret::createFolds(pca_LPW$length, k = 10, list = TRUE, returnTrain = FALSE)
PCR_errors <- vector()
# GAM
for(i in 1:10){
  mod <- lm(data = pca_LPW[-splits[[i]],], length ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
  preds <- predict(mod, newdata = pca_LPW[splits[[i]],])
  PCR_errors[i] <- RMSE(pca_LPW[splits[[i]],]$length, preds)
}
# RMSE
mean(PCR_errors)

# PCR with only significant PC's from lm() summary
for(i in 1:10){
  mod <- lm(data = pca_LPW[-splits[[i]],], length ~ PC1 + PC2 + PC5 + PC6 + PC8 + PC10)
  preds <- predict(mod, newdata = pca_LPW[splits[[i]],])
  PCR_errors2[i] <- RMSE(pca_LPW[splits[[i]],]$length, preds)
}
#RMSE
mean(PCR_errors2)

# choosing the best PC's for length results in lowest RMSE

pred <- predict(PCR_length2,pca_LPW[splits[[1]],])
ggplot() +  # fitted values vs actual, out of sample prediction in red
  geom_point(aes(pca_LPW[splits[[1]],]$length,PCR_length2$fitted.values)) + 
  geom_point(aes(test$length,PCR_length_split_pred),col = "red") + 
  geom_abline(slope=1, intercept = 0, col = "red")

# Split for PCR
set.seed(1)
idx <- floor(nrow(scan_avg) * 0.9) # 90% of indices needed for training set
train_idx <- sample(seq_len(nrow(scan_avg)), size = idx) # generate indices for training set
train <- scan_avg[train_idx, -c(1, 3:20)] # length and wavenumber measurement columns only
test <- scan_avg[-train_idx, -c(1, 3:20)]

# PCR model 
pcr_length_model <- pls::pcr(length ~ .,
  data = train,
  scale = T,
  validation = "CV",
  ncomp = 10
) # look at 10 components max
selectNcomp(pcr_length_model, "onesigma", plot = TRUE) # determine appropriate number of comps
scoreplot(pcr_length_model) # plot of first 2 PCs
loadingplot(pcr_length_model)

pcr_length_pred <- predict(pcr_length_model, newdata = test, ncomp = 2) # fit model to test data, store fitted values
ggplot() +
  geom_point(aes(x = train$length, y = pcr_length_model$fitted.values[, , 2])) + # extract fitted values of model with 2 PCs.
  geom_point(aes(x = test$length, y = pcr_length_pred), col = "red") +
  geom_abline(slope = 1, col = "red")

```

# PLS for Age

```{r}
# df with only aged specimens
age_only <- scan_avg[complete.cases(scan_avg$read_age),]

# test pls, no variable selection
test_pls_age <- pls(age_only[, 21:ncol(age_only)], age_only[, 11],
  scale = F, center = T, info = "Age Prediction Model",
  cv = 1
)
plot(test_pls_age)
# pls with VIP > 1
test_vip_age <- vipscores(test_pls_age)
plotVIPScores(test_pls_age)
good_waves <- as.numeric(names(subset(test_vip_age[,1], test_vip_age[,1] > 1)))
all_waves <- names(age_only[,21:length(age_only)])
bad_waves <- all_waves[!(all_waves %in% good_waves)]

test_pls_age_VIP <- pls(age_only[, 21:ncol(age_only)], age_only[, 11],
 scale = F, center = T, info = "Age Prediction Model",
 cv = 1, exclcols = bad_waves
)

# 90/10 split for PLS, no VIP
set.seed(1)
idx <- floor(nrow(age_only) * 0.9)
train_idx <- sample(seq_len(nrow(age_only)), size = idx)
train <- age_only[train_idx, -c(1:10,12:20)]
test <- age_only[-train_idx, -c(1:10,12:20)]

test_pls_age_split <- pls(train[,-1], train[,1],
  scale = F, center = T,
  info = "Age Prediction Model", cv = 1,
  x.test = test[,-1], y.test = test[,1]
)

# 90/10 split for PLS, VIP > 1
test_pls_age_split_VIP <- pls(train[,-1], train[,1],
  scale = F, center = T,
  info = "Age Prediction Model", cv = 1,
  x.test = test[,-c(1)], y.test = test[,1],
  exclcols = bad_waves
)

plot(test_pls_age)
plot(test_pls_age_VIP)
plot(test_pls_age_split)
plot(test_pls_age_split_VIP)

test_pls_age$res$cal$rmse[3]
test_pls_age_VIP$res$cal$rmse[2]
test_pls_age_split$res$test$rmse[3]
test_pls_age_split_VIP$res$cal$rmse[2]
```

# Other unorganized code

```{r}
pca_LPW <- pca(scan_avg_filter[,31:ncol(scan_avg_filter)], scale = F, center = T)
plot(pca_LPW)
plotVariance(pca_LPW$res$cal, type = "h", show.labels = TRUE, labels = "values")
# MDAtools PCA match prcomp output
pca_LPW$calres$scores[,1]
scan_avg_filter[,1]

data(simdata)
Xc = simdata$spectra.c
Xt = simdata$spectra.t
m = pca(Xc, 7, x.test = Xt)

PCA_res <- list()
PCA_test <- list()
for (i in 1:10) {
  Xc = scan_avg_filter[-splits[[i]], 31:ncol(scan_avg_filter)]
  Xt = scan_avg_filter[splits[[i]], 31:ncol(scan_avg_filter)]
  test_pca <- pca(Xc, scale = F, center = T, x.test = Xt)
  PCA_res[[i]] <- test_pca$calres$scores[,1:5]
  PCA_test[[i]] <- test_pca$testres$scores[,1:5]
}

# pca and pcares
lm(data=scan_avg_filter, length ~ )


plot(testing)
testing$testres

# PCR 
set.seed(1)
inTraining <- createDataPartition(scan_avg_filter$length, p = .9, list = F)
training <- scan_avg_filter[inTraining,-c(11,13:30)]
testing  <- scan_avg_filter[-inTraining,-c(11,13:30)]
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
pcr1 <- train(length ~ ., data = training, 
                 method = "pcr", 
                 trControl = fitControl)
pcr1$results
# RMSE for predictions
RMSE(predict(pcr1,testing),testing$length)
pcr1


# PLS
set.seed(1)
inTraining <- createDataPartition(scan_avg$length, p = .9, list = F)
training <- scan_avg[inTraining,-c(1,3:20)]
testing  <- scan_avg[-inTraining,-c(1,3:20)]
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
pls1 <- train(length ~ ., data = training,
              method = "widekernelpls",
              trControl = fitControl,
             )
pls1
postResampleSpectro(predict(pls1,testing),testing$length)


# PLS
set.seed(1)
inTraining <- createDataPartition(scan_avg$length, p = .9, list = F)
training <- scan_avg[inTraining,-c(1,3:20)]
testing  <- scan_avg[-inTraining,-c(1,3:20)]
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
pls2 <- train(x = scan_avg[,21:ncol(scan_avg)],
              y = scan_avg$length,
              method = "pls", 
              tuneLength = 6)
pls2
postResampleSpectro(predict(pls2,testing),testing$length)


##### NOW WITH MY DOGSHIT AGES ###### 

# 10 fold CV split, GAMS for age with RMSE
set.seed(1)
splits <- caret::createFolds(mlr_age_pcs$length, k = 10, list = TRUE, returnTrain = FALSE)
gam_errors <- vector()
mean(gam_errors)
# GAM
for(i in 1:10){
  mod <- gam(data = pca_LPW[-splits[[i]],], length ~ s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5), method="REML", select = T)
  preds <- predict(length_gam, newdata = pca_LPW[splits[[i]],])
  gam_errors[i] <- RMSE(pca_LPW[splits[[i]],]$length, preds)
}
#RMSE
mean(gam_errors)





PCR_length_split_pred <- predict(PCR_length_split,test)
ggplot() +  # fitted values vs actual, out of sample prediction in red
  geom_point(aes(train$length,PCR_length_split$fitted.values)) + 
  geom_point(aes(test$length,PCR_length_split_pred),col = "red") + 
  geom_abline(slope=1, intercept = 0, col = "red")







pca_LPW <- pca(scan_avg_rem[21:ncol(scan_avg)], scale = T) # PCA for scan_avg
plot(pca_LPW)
pca_LPW <- pca_LPW$calres$scores[, 1:20] # extract PCs
pca_LPW <- cbind(pca_LPW[, 1:5], scan_avg[, 1:4]) # only store first 5 PC's
colnames(pca_LPW)[c(1:5)] <- c("PC1", "PC2", "PC3", "PC4", "PC5")
PCR_length <- lm(data = pca_LPW, length ~ PC1 + PC2 + PC3 + PC4 + PC5)
summary(PCR_length) # only appear to need first 2 comps
PCR_length <- update(PCR_length, length ~ PC1 + PC2)
summary(PCR_length)


test <- AIC.summary %>% group_by(model) %>% summarise(meanAIC = mean(AIC),
                                              meanAICc = mean(AICc))
test


```
# Trying some things with other kinds of preprocessing.  Doing savitzky-golay and then a follow-up SNV
```{r}
scan_2 <- dfmeta_LPW %>% dplyr::filter(run_number == 2)
# scan_2_long <- pivot_longer(scan_2, cols = `11536`:`3952`, names_to = "name", values_to = "value")
# scan_2_long$name <- as.numeric(scan_2_long$name)
scan_3 <- dfmeta_LPW %>% dplyr::filter(run_number == 3)
# scan_3_long <- pivot_longer(scan_3, cols = `11536`:`3952`, names_to = "name", values_to = "value")
# scan_3_long$name <- as.numeric(scan_3_long$name)
testing1 <- bind_cols(NULL, scan_2[, 1:20])
testing1 <- bind_cols(testing1, (scan_2[, 21:ncol(scan_2)] + scan_3[, 21:ncol(scan_3)]) / 2)
rm(scan_2, scan_3)
testing2 <- cbind(testing1[, c(1:20)],savitzkyGolay(testing1[,21:ncol(testing1)],m = 1, p = 3, w = 17))
testing3 <- prep.snv(as.matrix(testing2[,21:ncol(testing2)]))
testing3 <- as.data.frame(unlist(testing3))
testing3 <- cbind(testing2[,1:20], testing3)

testing_long <- pivot_longer(testing1, cols = `11536`:`3952`, names_to = "name", values_to = "value")
testing_long$name <- as.numeric(testing_long$name)

testing_long2 <- pivot_longer(testing2, cols = `11472`:`4016`, names_to = "name", values_to = "value")
testing_long2$name <- as.numeric(testing_long2$name)

testing_long3 <- pivot_longer(testing3, cols = `11472`:`4016`, names_to = "name", values_to = "value")
testing_long3$name <- as.numeric(testing_long3$name)

ggplot(testing_long[complete.cases(testing_long$read_age), ], aes(x = name, y = value, group = specimen, color = read_age)) + 
  geom_path() + 
  scale_x_reverse() + 
  scale_color_viridis() + 
  labs(color = "Age (days)") + 
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1))) + 
  theme(axis.title = element_text(size = 18),
        axis.text = element_text(size = 15),
        legend.text = element_text(size = 10, vjust = .2),
        legend.title = element_text(size = 15, vjust = 1))

ggplot(testing_long2[complete.cases(testing_long2$read_age), ], aes(x = name, y = value, group = specimen, color = read_age)) + 
  geom_path() + 
  scale_x_reverse() + 
  scale_color_viridis() + 
  labs(color = "Age (days)") + 
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1))) + 
  theme(axis.title = element_text(size = 18),
        axis.text = element_text(size = 15),
        legend.text = element_text(size = 10, vjust = .2),
        legend.title = element_text(size = 15, vjust = 1))

ggplot(testing_long3[complete.cases(testing_long3$read_age), ], aes(x = name, y = value, group = specimen, color = read_age)) + 
  geom_path() + 
  scale_x_reverse() + 
  scale_color_viridis() + 
  labs(color = "Age (days)") + 
  labs(y = "Preprocessed absorbance", x = expression(paste("Wavenumber ", cm^-1))) + 
  theme(axis.title = element_text(size = 18),
        axis.text = element_text(size = 15),
        legend.text = element_text(size = 10, vjust = .2),
        legend.title = element_text(size = 15, vjust = 1))

unproc <- cbind(mod.summary,AIC.summary)


```

```{r, echo = F, results=F}
# Create dataframe only with ages contained in metadata
age_only <- testing2[complete.cases(testing2$read_age), ]

age_only <- age_only[,-c(21:517)]

# outliers identified with plotly and PCA
# SG
age_only <- age_only %>%
dplyr::filter(read_age != 188, read_age != 181, read_age != 175, read_age != 161, read_age != 148, read_age != 147, read_age != 135)

# store metrics from each fold and each model type
RMSE.age <- list()
r2.age <- list()
AIC.age <- list()
AICc.age <- list()

# 10 fold CV split - create folds
set.seed(6)
splits <- caret::createFolds(age_only$read_age, k = 10, list = TRUE, returnTrain = FALSE)

# extract PC's for each calibration set, create test sets with ages and spectra
cal <- list()
test <- list()
for (i in 1:10) {
  # calibration set and PC's
  pc.mod <- preProcess(age_only[-splits[[i]], -c(1:20)], method = "pca", thresh = 0.95, pcaComp = 10)
  pc.cal <- predict(pc.mod, age_only[-splits[[i]], -c(1:20)])
  pc.cal <- cbind(pc.cal, age_only[-splits[[i]], ])
  cal[[i]] <- pc.cal
  # test sets
  pc.test <- predict(pc.mod, age_only[splits[[i]], -c(1:20)])
  pc.test <- cbind(pc.test, age_only[splits[[i]], ])
  test[[i]] <- pc.test
}
rm(pc.cal,pc.test)

# determine which PC's to include via step & AIC selection
mod.sel <- list()
for (i in 1:10) {
  pctest <- cal[[i]]
  temp <- step(lm(data = pctest[-splits[[i]], ], read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10))
  mod.sel[[i]] <- rownames(summary(temp)$coef)
}

# PICK MODEL BASED ON TOP 5 AIC - worse performance than just using 4 PC's

# lm() with 10-fold CV
lm.mods <- list()
for (i in 1:10) {
  PC_5 <- sort(table(mod.sel[i]),decreasing = T)
  PC_5 <- rownames(PC_5)[2:6] # top 5 PC's
  PC_5 <- PC_5[complete.cases(PC_5)] # make sure not NA's
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- lm(data = calibrate, reformulate(PC_5, "read_age"))
  # RMSE.age$lm.cal[i] <- caret::RMSE(pred = mod$fitted.values, obs = calibrate[, 21])
  preds <- predict(mod, newdata = testing)
  RMSE.age$lm.test[i] <- caret::RMSE(pred = preds, obs = testing[, 21])
  # r2.age$lm.cal[i] <- summary(mod)$r.squared
  RSS <- sum((testing$read_age - preds)^2)
  TSS <- sum((testing$read_age - mean(testing$read_age))^2)
  r2.age$lm.test[i] <- 1 - (RSS / TSS)
  AIC.age$lm[i] <- AIC(mod)
  AICc.age$lm[i] <- AICc(mod)
  lm.mods[[i]] <- mod
}
# RMSE.age$lm.cal <- mean(RMSE.age$lm.cal)
RMSE.age$lm.test <- mean(RMSE.age$lm.test)
# r2.age$lm.cal <- mean(r2.age$lm.cal)
r2.age$lm.test <- mean(r2.age$lm.test)

# GAM with 10 fold CV, select = T allows PCs to be penalized and effectively removed from model if appropriate. 
GAM.mods <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- gam(data = calibrate, read_age ~ s(PC1) + s(PC2) + s(PC3) + s(PC4), method = "REML", select = T)
  # Extract AIC, AICc, RMSE (cal & test) & r2 (cal & test)
  # RMSE.age$GAM.cal[i] <- caret::RMSE(pred = mod$fitted.values, obs = calibrate[, 21])
  preds <- predict(mod, newdata = testing)
  RMSE.age$GAM.test[i] <- caret::RMSE(pred = preds, obs = testing[, 21])
  # r2.age$gam.cal[i] <- summary(mod)$r.sq
  RSS <- sum((testing$read_age - preds)^2)
  TSS <- sum((testing$read_age - mean(testing$read_age))^2)
  r2.age$gam.test[i] <- 1 - (RSS / TSS)
  AIC.age$gam[i] <- AIC(mod)
  AICc.age$gam[i] <- AICc(mod)
  GAM.mods[[i]] <- mod
}
# r2.age$gam.cal <- mean(r2.age$gam.cal)
r2.age$gam.test <- mean(r2.age$gam.test)
# RMSE.age$GAM.cal <- mean(RMSE.age$GAM.cal)
RMSE.age$GAM.test <- mean(RMSE.age$GAM.test)

AIC.summary <- data.frame(
  model = c(rep("lm", 10), rep("gam", 10)),
  AIC = 1:20,
  AICc = 1:20
)
AIC.summary$AIC <- unlist(AIC.age)
AIC.summary$AICc <- unlist(AICc.age)

# LM
mean(AIC.summary[1:10,2]) # AIC
mean(AIC.summary[1:10,3]) # AICc

# GAM
mean(AIC.summary[11:20,2]) # AIC
mean(AIC.summary[11:20,3]) # AICc


```
# PLS OF DIFFERENT PREPROCESSING
```{r}
sg.snv.results <- cbind(mod.summary,AIC.summary)

PCA.unproc <- ggplot() + 
  geom_point(data = test[[5]], aes(x = PC1, y = PC2, color = read_age), size = 5) +
  geom_point(data = cal[[5]], aes(x = PC1, y = PC2, color = read_age), size = 5) + 
  scale_color_viridis() + 
  theme_bw() + 
  theme(
    axis.title = element_text(size = 25),
    axis.text = element_text(size = 20),
    legend.text = element_text(size = 15, color = "black"),
    legend.title = element_text(size = 18),
    legend.position.inside = c(0.85, 0.8)) +
  labs(color = "Age (days)")

PCA.unproc
```

```{r}
library(plotly)

ggplotly(PCA.unproc) # outliers that are obvious: 188, 184, 181, 147
ggplotly(PCA.sg) # 188, 181, 175, 161, 148, 147, 135
ggplotly(PCA.snv) # 188, 181, 161, 148, 147, 135?

rm(sg.PCA)

unproc

results

results.sg %>% group_by(model) %>% summarize(r2 = mean(r2), RMSE = mean(RMSE))


pca_test <- mdatools::pca(age_only[,21:ncol(age_only)])
plot(pca_test)
outliers <- which(categorize(m, m$res$cal) == "extreme")



test <- categorize(m, m$res$cal)
which(test == c("extreme","outlier"))

m <- pls.mods[[1]]
outliers <- which(categorize(m, m$res$cal) == "extreme")
outliers2 <- which(categorize(m, m$res$cal) == "outlier")
c(which(categorize(m, m$res$cal) == "extreme"),which(categorize(m, m$res$cal) == "outlier"))

rbind()
outliers <- cat(which(categorize(m, m$res$cal) == "extreme"), cat(which(categorize(m, m$res$cal) == "outlier")))


which(categorize(m, m$res$cal) == c("outlier","extreme"))


m <- pca_test
c = categorize(m, m$res$cal)
print(c)

par(mfrow = c(1, 2))
plotExtreme(pca_test, comp = 1, main = "Extreme plot (cal)")
plotExtreme(pca_test, comp = 2:3, res = pca_test$res$test, main = "Extreme plot (test)")

pca_test$res$cal
```

```{r}
n<-50 # number of observations
p<-5 # number of variables
X<-matrix(rnorm(n*p),ncol=p)
y<-rnorm(n)

# compute linear PLS
pls.object<-pls.ic(X,y,m=ncol(X))

library(plsdof)
library(plsRglm)

?plsRglm

install.packages("plsRglm")
broom::tidy(summary(pls.mods[[1]]))


gratia::draw(GAM.mods[[5]],residuals = T)
plot(pls.mods[[5]])

cal[5]

calibrate <- age_only[-splits[[1]], ]
test <- age_only[splits[[1]], ]


x <- calibrate[, 31:ncol(calibrate)]
y <- calibrate[, "read_age"]

summary(pls.mods[[1]]$calres)
plot(pls.mods[[1]])

modpls <-plsR(y,x,2)
test.dof <- plsR.dof(testing)
aic.dof(modpls$RSS,modpls$nr,dof.object$DoF,dof.object$sigmahat)
bic.dof(modpls$RSS,modpls$nr,dof.object$DoF,dof.object$sigmahat)

aic.dof(testing,2)


dof.object <- plsR.dof(modpls)
aic.dof(modpls$RSS,modpls$nr,dof.object$DoF,dof.object$sigmahat)
bic.dof(modpls$RSS,modpls$nr,dof.object$DoF,dof.object$sigmahat)
gmdl.dof(dof.object$sigmahat,modpls$nr,dof.object$DoF,dof.object$yhat)
naive.object <- plsR.dof(modpls,naive=TRUE)
aic.dof(modpls$RSS,modpls$nr,naive.object$DoF,naive.object$sigmahat)
bic.dof(modpls$RSS,modpls$nr,naive.object$DoF,naive.object$sigmahat)
gmdl.dof(naive.object$sigmahat,modpls$nr,naive.object$DoF,naive.object$yhat)




mod <- pls(calibrate[, 31:ncol(calibrate)], calibrate[, "read_age"],
           ncomp.selcrit = "wold", scale = F, center = T, cv = 1,
           info = "Age Prediction Model",
           x.test = testing[, 31:ncol(testing)], 
           y.test = testing[, "read_age"])
ncomp <- mod$ncomp.selected



data(Cornell)
XCornell<-Cornell[,1:7]
yCornell<-Cornell[,8]

#maximum 6 components could be extracted from this dataset
#trying 10 to trigger automatic stopping criterion
modpls10<-plsR(yCornell,XCornell,10)
modpls10




```


```{r}


##### PCA functions for plotting and other stuff from old code ####

pca.var <- function(mydf, mypca) {
  PC1perc <<- round(mypca$eigenvals[1] / sum(mypca$eigenvals), digits = 4) * 100
  PC2perc <<- round(mypca$eigenvals[2] / sum(mypca$eigenvals), digits = 4) * 100
  varsc0 <- as.data.frame(mypca$loadings[, 1:3])
  objsc0 <- as.data.frame(mypca$calres$scores[, 1:3])
  Spectrascores_all <- as.data.frame(cbind(objsc0$`Comp 1`, objsc0$`Comp 2`, objsc0$`Comp 3`))
  colnames(Spectrascores_all) <- c("PCs1", "PCs2", "PCs3")
  SpecVec <- as.data.frame(cbind(varsc0$`Comp 1`, varsc0$`Comp 2`, varsc0$`Comp 3`))
  head(SpecVec)
  colnames(SpecVec) <- c("PC1", "PC2", "PC3")
  Spectrascores_all <- cbind(Spectrascores_all, mydf[, 1:8])
}


PCA.plot <- function(mydf, mypca, color.by) {
  temp <- pca.var(mydf = mydf, mypca = mypca)
  ggplot() +
    geom_hline(yintercept = 0, color = "gray") +
    geom_vline(xintercept = 0, color = "gray") +
    geom_point(data = temp, aes(x = PCs1, y = PCs2, color = {{ color.by }}), size = 3) +
    labs(x = paste("PC1 (", PC1perc, "%)", sep = ""), y = paste("PC2 (", PC2perc, "%)", sep = "")) +
    scale_color_viridis_c() +
    theme(
      panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text = element_text(size = 16),
      axis.title = element_text(size = 16, face = "bold"),
      legend.text = element_text(size = 12),
      legend.title = element_text(size = 10.5),
      plot.title = element_text(size = 16, face = "bold"),
      strip.text.x = element_text(size = 14)
    )
}


PCA.plot.bigger <- function(mydf, mypca, color.by) {
  temp <- pca.var(mydf = mydf, mypca = mypca)
  ggplot() +
    geom_hline(yintercept = 0, color = "gray") +
    geom_vline(xintercept = 0, color = "gray") +
    geom_point(data = temp, aes(x = PCs1, y = PCs2, color = {{ color.by }}), size = 5) +
    labs(
      x = paste("PC1 (", PC1perc, "%)", sep = ""),
      y = paste("PC2 (", PC2perc, "%)", sep = "")
    ) +
    scale_color_viridis_c() +
    theme(
      panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text = element_text(size = 16),
      axis.title = element_text(size = 16, face = "bold"),
      legend.text = element_text(size = 12),
      legend.title = element_text(size = 10.5),
      plot.title = element_text(size = 16, face = "bold"),
      strip.text.x = element_text(size = 14)
    )
}

mypca <- pca(age_only[,21:ncol(age_only)], scale = F, center = T)
plotVariance(mypca)
plot(mypca)
PC1perc <<- round(mypca$eigenvals[1] / sum(mypca$eigenvals), digits = 4) * 100
PC2perc <<- round(mypca$eigenvals[2] / sum(mypca$eigenvals), digits = 4) * 100
varsc0 <- as.data.frame(mypca$loadings[, 1:3])
objsc0 <- as.data.frame(mypca$calres$scores[, 1:3])
Spectrascores_all <- as.data.frame(cbind(objsc0$`Comp 1`, objsc0$`Comp 2`, objsc0$`Comp 3`))
colnames(Spectrascores_all) <- c("PCs1", "PCs2", "PCs3")
SpecVec <- as.data.frame(cbind(varsc0$`Comp 1`, varsc0$`Comp 2`, varsc0$`Comp 3`))
head(SpecVec)
colnames(SpecVec) <- c("PC1", "PC2", "PC3")
Spectrascores_all <- cbind(Spectrascores_all, read_age = age_only[,11])
fig <- ggplot() +
  geom_hline(yintercept = 0, color = "gray") +
  geom_vline(xintercept = 0, color = "gray") +
  geom_point(data = Spectrascores_all, aes(x = PCs1, y = PCs2, color = read_age), size = 3) +
  labs(x = paste("PC1 (", PC1perc, "%)", sep = ""), y = paste("PC2 (", PC2perc, "%)", sep = "")) +
  scale_color_viridis_c() +
  theme(
    panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text = element_text(size = 16),
    axis.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 12),
    legend.title = element_text(size = 10.5),
    plot.title = element_text(size = 16, face = "bold"),
    strip.text.x = element_text(size = 14)
  )
#library(plotly)
ggplotly(fig)




##### JUNK OUTLIERS AND PCA PLOTTING #####



# potential outliers: 53(age 175), 52(age 135)
# other junk ages maybe (148 (44 in spectrascores), 147)
age_only_original <- age_only
age_only <- age_only %>% dplyr::filter(read_age != 175 & read_age != 135 & read_age != 146 & 
                                         specimen != 65)


mypca <- pca(temp_ages[,21:ncol(temp_ages)], scale = F, center = T)
PC1perc <<- round(mypca$eigenvals[1] / sum(mypca$eigenvals), digits = 4) * 100
PC2perc <<- round(mypca$eigenvals[2] / sum(mypca$eigenvals), digits = 4) * 100
varsc0 <- as.data.frame(mypca$loadings[, 1:3])
objsc0 <- as.data.frame(mypca$calres$scores[, 1:3])
Spectrascores_all <- as.data.frame(cbind(objsc0$`Comp 1`, objsc0$`Comp 2`, objsc0$`Comp 3`))
colnames(Spectrascores_all) <- c("PCs1", "PCs2", "PCs3")
SpecVec <- as.data.frame(cbind(varsc0$`Comp 1`, varsc0$`Comp 2`, varsc0$`Comp 3`))
colnames(SpecVec) <- c("PC1", "PC2", "PC3")
Spectrascores_all <- cbind(Spectrascores_all, read_age = temp_ages[,11])
fig <- ggplot() +
  geom_hline(yintercept = 0, color = "gray") +
  geom_vline(xintercept = 0, color = "gray") +
  geom_point(data = Spectrascores_all, aes(x = PCs1, y = PCs2, color = read_age), size = 3) +
  labs(x = paste("PC1 (", PC1perc, "%)", sep = ""), y = paste("PC2 (", PC2perc, "%)", sep = "")) +
  scale_color_viridis_c() +
  theme(
    panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.text = element_text(size = 16),
    axis.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 12),
    legend.title = element_text(size = 10.5),
    plot.title = element_text(size = 16, face = "bold"),
    strip.text.x = element_text(size = 14)
  )
ggplotly(fig)


AIC(fit.lm, fit.gam)

fit.lm <- lm(data = pctest[-splits[[1]],], read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
fit.gam <- gam(data = pctest[-splits[[1]],], read_age ~ s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5) + s(PC6) + s(PC7) + s(PC8) + s(PC9) + s(PC10), method="ML", select = T)

fit.gam$aic
AIC(fit.gam)


bs="cs"

#### BRANCH FIT FROM LAB 10 MODEL SELECTION FOR GETTING AIC COMPARISONS: NOT USABLE WITH PLS!!!!! ####

# 
# Branch.fits <- vector("list")
# Branch.fits$A <- lm(data = pctest[-splits[[1]],], read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
# step(Branch.fits$A)
# 
# 
# 
# 
# Branch.fits$B <- lm(logRS ~ S + SST.t2 + SST.t3 + PDO.t2 + PDO.t3, data=Branch, x=T)
# Branch.fits$C <- lm(logRS ~ S + SST.t2 + SST.t3 + regime, data=Branch, x=T)
# Branch.fits$D <- lm(logRS ~ S + SST.t2 + SST.t3, data=Branch, x=T)
# Branch.fits$E <- lm(logRS ~ S + PDO.t2 + PDO.t3, data=Branch, x=T)
# Branch.fits$F <- lm(logRS ~ S + regime, data=Branch, x=T)
# Branch.fits$G <- lm(logRS ~ S, data=Branch, x=T)
# 
# 
# aictab(Branch.fits, names(Branch.fits))          # small-sample AICc (default)
# aictab(Branch.fits, names(Branch.fits), sec=F) 
# 
# 
# out <- matrix(NA, 7, 7)
# dimnames(out) <- list(names(Branch.fits), c("k", "R2", "logL", "AIC", "delAIC", "AICc", "delAICc"))
# 
# for(i in names(Branch.fits)) {
#   mod <- Branch.fits[[i]]
#   logL <- logLik(mod)
#   out[i, "k"] <-  attr(logL, "df")
#   out[i, "R2"] <- summary(mod)$r.sq
#   out[i,"logL"] <- logL
#   out[i,"AIC"] <- AIC(mod)
#   out[i, "AICc"] <- AICc(mod)
# }
# out
# 
# # Subtract minimum AIC (best model) from all values:
# out[,"delAIC"] <- out[,"AIC"] - min(out[,"AIC"])
# out[,"delAICc"] <- out[,"AICc"] - min(out[,"AICc"])
# round(out,2)
# 
# 




####    TRY WITH LENGTH TO SEE HOW IT PERFORMS!~!!>?!?!!?!? ####


# 10 fold CV split - create folds
set.seed(6)
splits <- caret::createFolds(scan_avg_filter$length, k = 10, list = TRUE, returnTrain = FALSE)


# extract PC's for each calibration set, create test sets with ages and spectra
cal <- list()
test <- list()
for(i in 1:10){
  # calibration set and PC's
  pc.mod <- preProcess(scan_avg_filter[-splits[[i]],-c(1:20)], method = "pca", thresh = 0.95, pcaComp = 10)
  pc.cal <- predict(pc.mod, scan_avg_filter[-splits[[i]],-c(1:20)])
  pc.cal <- cbind(pc.cal, scan_avg_filter[-splits[[i]],])
  cal[[i]] <- pc.cal
  # test sets
  pc.test <- predict(pc.mod, scan_avg_filter[splits[[i]],-c(1:20)])
  pc.test <- cbind(pc.test, scan_avg_filter[splits[[i]],])
  test[[i]] <- pc.test
}


# store metrics from each fold and each model type
RMSE.length <- list() 
r2.length <- list() 
AIC.length <- list()
AICc.length <- list()

# determine which PC's to include via step & AIC selection
mod.sel <- list()
for(i in 1:10){
  pctest <- cal[[i]]
  temp <- step(lm(data = pctest[-splits[[i]],], length ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10))
  mod.sel[[i]] <- rownames(summary(temp)$coef)
}
table(unlist(mod.sel))

# PC 1, 2, 6, 9 are most informative???  Could include 3, 4, 7 & 8 possibly. Exclude 10 and 5 for now

lm.mods <- list()
for(i in 1:10){
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- lm(data = calibrate, length ~ PC1 + PC2 + PC6 + PC9)
  RMSE.length$lm.cal[i] <- caret::RMSE(pred = mod$fitted.values, obs = calibrate[,12])
  preds <- predict(mod, newdata = testing)
  RMSE.length$lm.test[i] <-  caret::RMSE(pred = preds, obs = testing[,12])
  r2.length$lm.cal[i] <- summary(mod)$r.squared
  RSS <- sum((testing$length - preds)^2)
  TSS <- sum((testing$length - mean(testing$length))^2)
  r2.length$lm.test[i] <- 1 - (RSS/TSS)
  AIC.length$lm[i] <- AIC(mod)
  AICc.length$lm[i] <- AICc(mod)
  lm.mods[[i]] <- mod
}

RMSE.length$lm.cal <- mean(RMSE.length$lm.cal)
RMSE.length$lm.test <- mean(RMSE.length$lm.test)
r2.length$lm.cal <- mean(r2.length$lm.cal)
r2.length$lm.test <- mean(r2.length$lm.test)



GAM.mods <- list()
# GAM with 10 fold split

for(i in 1:10){
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- gam(data = calibrate, length ~ s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5) + s(PC6) + s(PC7) + s(PC8) + s(PC9) + s(PC10), method="ML", select = T)
  # Extract AIC, AICc, RMSE (cal & test) & r2 (cal & test)
  RMSE.length$GAM.cal[i] <- caret::RMSE(pred = mod$fitted.values, obs = calibrate[,12])
  preds <- predict(mod, newdata = testing)
  RMSE.length$GAM.test[i] <- caret::RMSE(pred = preds, obs = testing[,12])
  r2.length$gam.cal[i] <- summary(mod)$r.sq
  RSS <- sum((testing$length - preds)^2)
  TSS <- sum((testing$length - mean(testing$length))^2) 
  r2.length$gam.test[i] <- 1 - (RSS/TSS)
  AIC.length$gam[i] <- AIC(mod)
  AICc.length$gam[i] <- AICc(mod)
  GAM.mods[[i]] <- mod
}
r2.length$gam.cal <- mean(r2.length$gam.cal)
r2.length$gam.test <- mean(r2.length$gam.test)
RMSE.length$GAM.cal <- mean(RMSE.length$GAM.cal)
RMSE.length$GAM.test <- mean(RMSE.length$GAM.test)

##### PLS COMPARISON ####

pls.mods <- list()
# test pls, no variable selection
for(i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- pls(calibrate[,25:ncol(pctest)], calibrate[,15],
             scale = F, center = T,
             info = "Length Prediction Model", cv = 1,
             x.test = testing[,25:ncol(pctest)], y.test = testing[,15])
  RMSE.length$pls.cal[i] <- mod$calres$rmse[[3]]
  RMSE.length$pls.test[i] <- mod$testres$rmse[[3]]
  r2.length$pls.cal[i] <- mod$calres$r2[[3]]
  r2.length$pls.test[i] <- mod$testres$r2[[3]]
  # RSS <- sum((mod$calres$y.ref - mod$calres$y.pred[,3,])^2)
  # n <- length(mod$calres$y.ref)
  # AIC.length$pls[i] <- n * log(RSS/n) + (2 * mod$ncomp.selected)
  pls.mods[[i]] <- mod
}
RMSE.length$pls.cal <- mean(RMSE.length$pls.cal)
RMSE.length$pls.test <- mean(RMSE.length$pls.test)
r2.length$pls.cal <- mean(r2.length$pls.cal)
r2.length$pls.test <- mean(r2.length$pls.test)


mod.summary <- data.frame(model = c("lm_cal", "lm_test", "gam_cal", "gam_test", "pls_cal", "pls_test"),
                          r2 = 1:6,
                          RMSE = 1:6)
mod.summary$r2 <- unlist(r2.length)
mod.summary$RMSE <- unlist(RMSE.length)
# AIC.length$lm <- mean(AIC.length$lm)
# AIC.length$gam <- mean(AIC.length$gam)
# AIC.length$pls <- mean(AIC.length$pls)
AIC.summary <- data.frame(model = c(rep("lm",10),rep("gam",10)),
                          AIC = 1:20,
                          AICc = 1:20)
# AIC.length <- AIC.length[-3]
AIC.summary$AIC <- unlist(AIC.length)
AIC.summary$AICc <- unlist(AICc.length)






pls.mods <- list()
# test pls, no variable selection
for(i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  mod <- pls(calibrate[,25:ncol(pctest)], calibrate[,12],
             scale = F, center = T,
             info = "Length Prediction Model", cv = 1,
             x.test = testing[,31:ncol(pctest)], y.test = testing[,12])
  RMSE.length$pls.cal[i] <- mod$calres$rmse[[3]]
  RMSE.length$pls.test[i] <- mod$testres$rmse[[3]]
  r2.length$pls.cal[i] <- mod$calres$r2[[3]]
  r2.length$pls.test[i] <- mod$testres$r2[[3]]
  # RSS <- sum((mod$calres$y.ref - mod$calres$y.pred[,3,])^2)
  # n <- length(mod$calres$y.ref)
  # AIC.length$pls[i] <- n * log(RSS/n) + (2 * mod$ncomp.selected)
  pls.mods[[i]] <- mod
}




#### OLD JUNK FROM RMD ####


# determine which PC's to include via step & AIC selection
mod.sel <- list()
for(i in 1:10){
  pctest <- pcs[[i]]
  temp <- step(lm(data = pctest[-splits[[i]],], read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10))
  mod.sel[[i]] <- rownames(summary(temp)$coef)
}
table(unlist(mod.sel))

# 1, 3, 4, 5 & 7 are most common, will start with those

lm.mods <- list()
for(i in 1:10){
  pctest <- pcs[[i]]
  mod <- lm(data = pctest, read_age ~ PC1 + PC3 + PC4 + PC5 + PC7)
  RMSE.age$lm.cal[i] <- caret::RMSE(mod$fitted.values,pctest[-splits[[i]],21])
  RMSE.age$lm.test[i] <-  caret::RMSE(preds,pctest[splits[[i]],21])
  r2.age$lm.cal[i] <- summary(mod)$r.squared
  RSS <- sum((pctest[splits[[i]],]$read_age - preds)^2)
  TSS <- sum((pctest[splits[[i]],]$read_age - mean(pctest[splits[[i]],]$read_age))^2)
  r2.age$lm.test[i] <- 1 - (RSS/TSS)
  AIC.age$lm[i] <- AIC(mod)
  AICc.age$lm[i] <- AICc(mod)
  lm.mods[[i]] <- mod
}
RMSE.age$lm.cal <- mean(RMSE.age$lm.cal)
RMSE.age$lm.test <- mean(RMSE.age$lm.test)
r2.age$lm.cal <- mean(r2.age$lm.cal)
r2.age$lm.test <- mean(r2.age$lm.test)

GAM.mods <- list()
# GAM with 10 fold split
for(i in 1:10){
  mod <- gam(data = pctest[-splits[[i]],], read_age ~ s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5) + s(PC6) + s(PC7) + s(PC8) + s(PC9) + s(PC10), method="ML", select = T)
  # Extract AIC, AICc, RMSE (cal & test) & r2 (cal & test)
  RMSE.age$GAM.cal[i] <- caret::RMSE(mod$fitted.values,pctest[-splits[[i]],21])
  preds <- predict(mod, newdata = pctest[splits[[i]],])
  RMSE.age$GAM.test[i] <- caret::RMSE(pctest[splits[[i]],]$read_age, preds)
  r2.age$gam.cal[i] <- summary(mod)$r.sq
  RSS <- sum((pctest[splits[[i]],]$read_age - preds)^2)
  TSS <- sum((pctest[splits[[i]],]$read_age - mean(pctest[splits[[i]],]$read_age))^2) 
  r2.age$gam.test[i] <- 1 - (RSS/TSS)
  AIC.age$gam[i] <- AIC(mod)
  AICc.age$gam[i] <- MuMIn::AICc(mod)
  GAM.mods[[i]] <- mod
}
r2.age$gam.cal <- mean(r2.age$gam.cal)
r2.age$gam.test <- mean(r2.age$gam.test)
RMSE.age$GAM.cal <- mean(RMSE.age$GAM.cal)
RMSE.age$GAM.test <- mean(RMSE.age$GAM.test)

##### PLS COMPARISON

pls.mods <- list()
# test pls, no variable selection
for(i in 1:10) {
  mod <- pls(pctest[-splits[[i]],c(31:ncol(pctest))], pctest[-splits[[i]],21],
             scale = F, center = T,
             info = "Age Prediction Model", cv = 1,
             x.test = pctest[splits[[i]],c(31:ncol(pctest))], y.test = pctest[splits[[i]],21])
  RMSE.age$pls.cal[i] <- mod$calres$rmse[[3]]
  RMSE.age$pls.test[i] <- mod$testres$rmse[[3]]
  r2.age$pls.cal[i] <- mod$calres$r2[[3]]
  r2.age$pls.test[i] <- mod$testres$r2[[3]]
  # RSS <- sum((mod$calres$y.ref - mod$calres$y.pred[,3,])^2)
  # n <- length(mod$calres$y.ref)
  # AIC.age$pls[i] <- n * log(RSS/n) + (2 * mod$ncomp.selected)
  pls.mods[[i]] <- mod
}
RMSE.age$pls.cal <- mean(RMSE.age$pls.cal)
RMSE.age$pls.test <- mean(RMSE.age$pls.test)
r2.age$pls.cal <- mean(r2.age$pls.cal)
r2.age$pls.test <- mean(r2.age$pls.test)


mod.summary <- data.frame(model = c("lm_cal", "lm_test", "gam_cal", "gam_test", "pls_cal", "pls_test"),
                          r2 = 1:6,
                          RMSE = 1:6)
mod.summary$r2 <- unlist(r2.age)
mod.summary$RMSE <- unlist(RMSE.age)
# AIC.age$lm <- mean(AIC.age$lm)
# AIC.age$gam <- mean(AIC.age$gam)
# AIC.age$pls <- mean(AIC.age$pls)
AIC.summary <- data.frame(model = c(rep("lm",10),rep("gam",10)),
                          AIC = 1:20,
                          AICc = 1:20)
# AIC.age <- AIC.age[-3]
AIC.summary$AIC <- unlist(AIC.age)
AIC.summary$AICc <- unlist(AICc.age)



# library(mdatools)
# mod <- plsr(read_age ~ .,
#             ncomp = 3,
#             data = test.df,
#             subset = test.sub,
#             scale = F, center = T)
# summary(mod)        
#               
#               , pctest[-splits[[1]],21],
#   scale = F, center = T,
#   info = "Age Prediction Model", cv = 1,
#   x.test = pctest[splits[[1]],c(31:ncol(pctest))], y.test = pctest[splits[[1]],21])
# 



b <- getViz(GAM.mods[[1]], nsim = 50)

gridPrint(check1D(b, "PC1") + l_gridCheck1D(gridFun = sd, showReps = TRUE), 
          check1D(b, "PC2") + l_gridCheck1D(gridFun = sd, showReps = TRUE), 
          check1D(b, "PC3") + l_gridCheck1D(gridFun = sd, showReps = TRUE),
          check1D(b, "PC4") + l_gridCheck1D(gridFun = sd, showReps = TRUE),ncol = 2)


(p <- predict_response(GAM.mods[[1]], terms=c("PC1")))
p %>% plot()


par(mfrow=c(2,2))
gam.check(GAM.mods[[5]])
par(mfrow=c(1,1))





draw(GAM.mods[[5]],select=2, residuals = T)


ggplot() +
  geom_point(data = test[[5]], aes(x = PC1, y = read_age), col = "red") + 
 # geom_smooth(method = "lm", data = test[[5]], aes(x = PC1, y = read_age), col = "red") + 
  geom_point(data = cal[[5]], aes(x = PC1, y = read_age), col = "black") +
  geom_smooth(data = cal[[5]], aes(x = PC1, y = read_age), method = "gam") #+

ggplot() +
  geom_point(data = test[[5]], aes(x = PC2, y = read_age), col = "red") + 
  #geom_smooth(method = "lm", data = test[[5]], aes(x = PC2, y = read_age), col = "red") + 
  geom_point(data = cal[[5]], aes(x = PC2, y = read_age), col = "black") + 
  geom_smooth(data = cal[[5]], aes(x = PC2, y = read_age), method = "gam") #+

ggplot() +
  geom_point(data = test[[5]], aes(x = PC3, y = read_age), col = "red") + 
  #geom_smooth(method = "lm", data = test[[5]], aes(x = PC3, y = read_age), col = "red") + 
  geom_point(data = cal[[5]], aes(x = PC3, y = read_age), col = "black") + 
  geom_smooth(data = cal[[5]], aes(x = PC3, y = read_age), method = "gam") +

ggplot() +
  geom_point(data = test[[5]], aes(x = PC4, y = read_age), col = "red") + 
#  geom_smooth(method = "lm", data = test[[5]], aes(x = PC4, y = read_age), col = "red") + 
  geom_point(data = cal[[5]], aes(x = PC4, y = read_age), col = "black")+ 
  geom_smooth(data = cal[[5]], aes(x = PC4, y = read_age), method = "gam")





draw(gam.select,residuals = T) & theme_stata() & 
  theme(plot.title = element_text(size = 22), axis.title = element_text(size = 20),axis.text = element_text(size = 18))


appraise(gam.select) & theme_stata() & 
  theme(plot.title = element_text(size = 22), axis.title = element_text(size = 20),axis.text = element_text(size = 18))

```

