I'm redoing my modelling approach a bit per Franz's suggestions.  The general approach will be: 
- start with the entire dataframe (no splits) and pick the number of PC's I would like to use. ~10 for LM and maybe less for GAM
- fit LM and GAM with PC's from the full dataset (MuMIn, dredge function)
- choose subset of best models, up to 5.
- 10-fold CV and evaluate top 5 models from each approach
- List all selected models and AIC from dredge function


```{r, results = 'hide', warning = F, message = F}
# Install packages not yet installed
packages <- c("caret", "corrplot", "dplyr","devtools", "DT", "dplyr", "gglm", "ggplot2", "gratia", "gridExtra", "knitr", "lubridate", "mdatools", "mgcv", "MuMIn", "opusreader2", "prospectr", "splitstackshape","shiny","shinyWidgets", "tidyr", "viridis")
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  utils::install.packages(pkgs = packages[!installed_packages])
}
invisible(lapply(packages, library, character.only = TRUE)) # load all packages in list
# install packages not on CRAN
if (!require("remotes")) install.packages("remotes")
if (!require("opusreader2")) {
  remotes::install_github("spectral-cockpit/opusreader2")
  library("opusreader2")
}
# if (!require("simplerspec")) {
#   remotes::install_github("philipp-baumann/simplerspec")
#   library("simplerspec")
# }
rm(installed_packages, packages) # remove objects from environment
```

# Load dataframe
I'm trying to decide whether to cutoff the wavenumbers >7500 since this region is relatively "noisy".  After some investigating I may opt to include this region as my models tend to fit a bit better.  Preprocessing tweaks don't seem to be making a huge different so opting for Matta et al's 1,3,17 for SG filter.
```{r, eval=FALSE}
# cut off >7500 wavenumber
# df_filter <- readRDS("RDS_dataframes/LPW_scan_avg_proc_filter.RDS")
df <- df_filter
# ALL wavenumbers
df <- readRDS("RDS_dataframes/LPW_scan_avg_proc.RDS")

# adjust preprocessing
# df <- readRDS("RDS_dataframes/LPW_scan_avg_unproc.RDS")
# df <- cbind(df[, c(1:20)], savitzkyGolay(df[, 21:length(df)], m = 1, p = 3, w = 17))
```

# 10 PCs, LM/GAM dredging with all samples

I've been trying to decide whether I want to select the best models based on PCA of spectra from ALL specimens (including those that are unaged), or only PCA's based on aged specimens.  I've played around with both and it appears that model selecting with only aged specimens may be performing slightly better. 

I had to reduce the number of PC's in my GAMs models to improve overall fit.  R2 values with 10 PCs were all over the place (large and/or negative), and fit seems to be better around 6 overall PC's for the dredge function.
```{r, eval=FALSE}
# unfiltered spectra
# remove unaged specimens before calculating PCs
df <- df[complete.cases(df$read_age), ]

pca_temp <- pca(df[, 21:ncol(df), ])
pc_df <- data.frame(PC1 = rep(0,nrow(df)))
for (i in 1:10) {
  pc_df[, paste0("PC", i)] <- pca_temp$res$cal$scores[, i]
  rm(i)
}
pc_df <- cbind(pc_df,df)
global_lm <- lm(data = pc_df, read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
global_gam <- gam(data = pc_df, read_age ~ s(PC1,k = 4) + s(PC2,k = 4) + s(PC3,k = 4) + s(PC4,k = 4) + s(PC5,k = 4) + s(PC6,k = 4) + s(PC7,k = 4) + s(PC7,k = 4) + s(PC8,k = 4) + s(PC9,k = 4) + s(PC10,k = 4)) # adding too many PC's makes GAM have horrible fit and R2


# s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5) + s(PC6)


# dredge to find top 5 models
options(na.action = "na.fail")
dredge_lm <- dredge(global_lm)
top5_lm <- get.models((dredge_lm), subset = 1:5)
dredge_gam <- dredge(global_gam)
top5_gam <- get.models(dredge_gam, subset = 1:5)
terms_lm <- list()
terms_gam <- list()
for(i in 1:5){
  terms_lm[[i]] <- top5_lm[[i]]$terms
  terms_gam[[i]] <- top5_gam[[i]]$formula
  rm(i)
}

# #### filter wavenumbers >7500
# df_filter <- df_filter[complete.cases(df_filter$read_age), ]
# pca_filter_temp <- pca(df_filter[, 21:ncol(df_filter), ])
# pc_filter_df <- data.frame(PC1 = rep(0,nrow(df_filter)))
# for (i in 1:10) {
#   pc_filter_df[, paste0("PC", i)] <- pca_filter_temp$res$cal$scores[, i]
#   rm(i)
# }
# pc_filter_df <- cbind(pc_filter_df,df_filter)
# global_lm_filter <- lm(data = pc_filter_df, read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
# global_gam_filter <- gam(data = pc_df_filter, read_age ~ s(PC1) + s(PC2) + s(PC3) + s(PC4) + s(PC5) + s(PC6))
# dredge_lm_filter <- dredge(global_lm_filter)
# top5_lm <- get.models((dredge_lm_filter), subset = 1:5)
# dredge_gam_filter <- dredge(global_gam_filter)
# top5_gam <- get.models(dredge_gam_filter, subset = 1:5)
# terms_lm <- list()
# terms_gam <- list()
# for(i in 1:5){
#   terms_lm[[i]] <- top5_lm[[i]]$terms
#   terms_gam[[i]] <- top5_gam[[i]]$formula
#   rm(i)
# }

rm(global_gam, global_lm, top5_gam, top5_lm, pc_df, pca_temp, dredge_gam,dredge_lm)
# rm(global_gam_filter, global_lm_filter, pc_filter_df, pca_filter_temp, dredge_gam_filter, dredge_lm_filter)
```

# 10-fold split

```{r message=FALSE, echo = T, results = 'hide', eval=FALSE}
# 10 fold CV split - create folds
set.seed(6)
splits <- caret::createFolds(df$read_age, k = 10, list = TRUE, returnTrain = FALSE)
# extract PC's for each calibration set, create test sets with ages and spectra
cal <- list()
test <- list()
for (i in 1:10) {
  # calibration set and PC's
  pc.mod <- preProcess(df[-splits[[i]], -c(1:20)], method = c("pca","center"), pcaComp = 10)
  pc.cal <- predict(pc.mod, df[-splits[[i]], -c(1:20)])
  pc.cal <- cbind(pc.cal, df[-splits[[i]], ])
  cal[[i]] <- pc.cal
  rm(pc.cal)
  # test sets
  pc.test <- predict(pc.mod, df[splits[[i]], -c(1:20)])
  pc.test <- cbind(pc.test, df[splits[[i]], ])
  test[[i]] <- pc.test
  rm(pc.test, pc.mod, i)
}
```

# LM - top 5 models

```{r message=FALSE, eval=FALSE}
mods.lm <- replicate(10, list())
r2_lm <- list()
rmse_lm <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  r2_temp <- rep(0, 5)
  rmse_temp <- rep(0, 5)
  for (j in 1:5) {
    mod <- lm(data = calibrate, terms_lm[[j]])
    preds <- predict(mod, newdata = testing)
    rmse_temp[j] <- caret::RMSE(pred = preds, obs = testing[, "read_age"])
    RSS <- sum((testing$read_age - preds)^2)
    TSS <- sum((testing$read_age - mean(testing$read_age))^2)
    r2_temp[j] <- 1 - (RSS / TSS)
    mods.lm[[i]][[j]] <- mod
    rm(RSS, TSS, preds)
  }
  r2_lm[[i]] <- data.frame(Model = paste0("Linear ", 1:5), r2 = r2_temp)
  rmse_lm[[i]] <- data.frame(Model = paste0("Linear ", 1:5), rmse = rmse_temp)
  rm(mod, i, j, r2_temp, rmse_temp, calibrate, testing)
}
# Unlist the r2 & rmse values and calc means for 10 splits, combine into dataframe
r2_lm <- sapply(r2_lm, "[[", "r2")
r2_lm <- rowMeans(r2_lm)
rmse_lm <- sapply(rmse_lm, "[[", "rmse")
rmse_lm <- rowMeans(rmse_lm)
(lm_result <- data.frame(
  Model = paste0("Linear ", 1:5),
  Mean_R2 = r2_lm,
  Mean_RMSE = rmse_lm
))
rm(r2_lm, rmse_lm)
```

# GAM - top 5 models

```{r, eval=FALSE}
mods.gam <- replicate(10, list())
r2_gam <- list()
rmse_gam <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  r2_temp <- rep(0, 5)
  rmse_temp <- rep(0, 5)
  for (j in 1:5) {
    mod <- gam(data = calibrate, terms_gam[[j]])
    preds <- predict(mod, newdata = testing)
    rmse_temp[j] <- caret::RMSE(pred = preds, obs = testing[, "read_age"])
    RSS <- sum((testing$read_age - preds)^2)
    TSS <- sum((testing$read_age - mean(testing$read_age))^2)
    r2_temp[j] <- 1 - (RSS / TSS)
    mods.gam[[i]][[j]] <- mod
    rm(RSS, TSS, preds)
  }
  r2_gam[[i]] <- data.frame(Model = paste0("GAM ", 1:5), r2 = r2_temp)
  rmse_gam[[i]] <- data.frame(Model = paste0("GAM ", 1:5), rmse = rmse_temp)
  rm(j, i, testing, calibrate, mod, r2_temp, rmse_temp)
}
r2_gam <- sapply(r2_gam, "[[", "r2")
r2_gam <- rowMeans(r2_gam)
rmse_gam <- sapply(rmse_gam, "[[", "rmse")
rmse_gam <- rowMeans(rmse_gam)
gam_result <- data.frame(
  Model = paste0("GAM ", 1:5),
  Mean_R2 = r2_gam,
  Mean_RMSE = rmse_gam
)
(results <- rbind(lm_result,gam_result))
rm(r2_gam, rmse_gam, lm_result, gam_result)
```

# PLS models
VIP scores to filter wavenumbers seems to always make model fit more poorly; likely will NOT be using.
```{r, eval=FALSE}
mods.pls <- list()
mods.vip <- list()
r2.pls <- list()
rmse.pls <- list()
for (i in 1:10) {
  calibrate <- df[-splits[[i]], ]
  testing <- df[splits[[i]], ]
  mod <- pls(calibrate[, 31:ncol(calibrate)], calibrate[, "read_age"],
    scale = F, center = T, cv = 1, #ncomp.selcrit = "wold", removing for now, seems too conservative with number of selected components
    info = "Age Prediction Model",
    x.test = testing[, 31:ncol(testing)],
    y.test = testing[, "read_age"]
  )
  ncomp <- mod$ncomp.selected
  rmse.pls$pls.test[i] <- mod$testres$rmse[[ncomp]] # extract rmse
  r2.pls$pls.test[i] <- mod$testres$r2[[ncomp]] # extract r2
  
  # VIP filter of wavenumbers
  mods.pls[[i]] <- mod
  mods.pls[[1]]$ncomp.selected
  vip <- as.data.frame(vipscores(mod))
  mod <- pls(calibrate[, 31:ncol(calibrate)], calibrate[, "read_age"],
    # ncomp.selcrit = "wold", 
    scale = F, center = T, cv = 1,
    info = "Age Prediction Model",
    x.test = testing[, 31:ncol(testing)],
    y.test = testing[, "read_age"],
    exclcols = vip$V1 < 0.5
  )
  ncomp <- mod$ncomp.selected
  r2.pls$vip.test[i] <- mod$testres$r2[[ncomp]] # extract r2
  mods.vip[[i]] <- mod
  rmse.pls$vip.test[i] <- mod$testres$rmse[[ncomp]] # extract rmse
  rm(calibrate, mod, ncomp, testing, i, vip)
}
(results <- rbind(results, 
                 c("PLS", mean(r2.pls$pls.test), mean(rmse.pls$pls.test)),
                 c("VIP", mean(r2.pls$vip.test), mean(rmse.pls$vip.test))
))
rm(rmse.pls, r2.pls)
```

# Look for potential outliers
Below are a couple approaches to find outliers I'm looking at without nit-picking via spectra and PCA.  Many of the specimens are borderline whether they should be removed or not, however I have previously seen that my largest specimen (#77, 182 cm) seems to throw off estimates and may be excluded from analysis.  
```{r}
df <- readRDS("RDS_dataframes/LPW_scan_avg_proc.RDS")
df <- df[complete.cases(df$read_age), ] 
# find outliers based on length and age - >2 SD
model <- lm(read_age ~ length, data = df)
df.temp <- df %>%
    mutate(residuals = resid(model))
residual_threshold <- 2 * sd(df.temp$residuals)
df.temp <- df.temp %>%
    mutate(outlier = ifelse(abs(residuals) > residual_threshold, TRUE, FALSE))
df.temp %>%
    ggplot(aes(x = length, y = read_age)) +
    geom_smooth(color = "#003d5b", 
                method = "lm", 
                se = FALSE,
                linewidth = 3,
                alpha = 0.2) +
    geom_point(aes(color = outlier), 
               size = 4, 
               alpha = 0.6,
               ) + 
    scale_color_manual(values = c("FALSE" = "#00798c", 
                                  "TRUE" = "#c1121f")) +
    ggrepel::geom_label_repel(
      data = filter(df.temp, outlier),
      aes(label = specimen),
      size = 3, 
      nudge_x = 0.1, 
      nudge_y = 0.1, 
      color = "#c1121f"
    ) +
    theme_minimal() + 
    labs(title = "length vs age",
         x = "length",
         y = "read age") +
    guides(color = guide_legend(override.aes = list(size = 4))) + 
    theme(text = element_text(size = 12),  # Default text size for all text elements
          plot.title = element_text(size = 20, face="bold"),  # Plot title
          axis.title = element_text(size = 16),  # Axis titles (both x and y)
          axis.text = element_text(size = 14),  # Axis text (both x and y)
          legend.title = element_text(size = 14),  # Legend title
          legend.text = element_text(size = 12))  # Legend items
# outs <- c(31,67,74,95)


# find outliers based on otolith weight and age - >2 SD
df.temp <- df[complete.cases(df$structure_weight), ] # filter only aged specimens
model <- lm(read_age ~ structure_weight, data = df.temp)
df.temp <- df.temp %>%
    mutate(residuals = resid(model))
residual_threshold <- 2 * sd(df.temp$residuals)
df.temp <- df.temp %>%
    mutate(outlier = ifelse(abs(residuals) > residual_threshold, TRUE, FALSE))
df.temp %>%
    ggplot(aes(x = structure_weight, y = read_age)) +
    geom_smooth(color = "#003d5b", 
                method = "lm", 
                se = FALSE,
                linewidth = 3,
                alpha = 0.2) +
    geom_point(aes(color = outlier), 
               size = 4, 
               alpha = 0.6,
               ) + 
    scale_color_manual(values = c("FALSE" = "#00798c", 
                                  "TRUE" = "#c1121f")) +
    ggrepel::geom_label_repel(
      data = filter(df.temp, outlier),
      aes(label = specimen),
      size = 3, 
      nudge_x = 0.1, 
      nudge_y = 0.1, 
      color = "#c1121f"
    ) +
    theme_minimal() + 
    labs(title = "structure_weight vs age",
         x = "structure_weight",
         y = "read age") +
    guides(color = guide_legend(override.aes = list(size = 4))) + 
    theme(text = element_text(size = 12),  # Default text size for all text elements
          plot.title = element_text(size = 20, face="bold"),  # Plot title
          axis.title = element_text(size = 16),  # Axis titles (both x and y)
          axis.text = element_text(size = 14),  # Axis text (both x and y)
          legend.title = element_text(size = 14),  # Legend title
          legend.text = element_text(size = 12))  # Legend items
# outs <- c(67,74,77,95)
```


# Run GAM and LM dredge with 3-10 PCs & store all results 


```{r}
# df <- readRDS("RDS_dataframes/LPW_scan_avg_proc.RDS")
df <- df[complete.cases(df$read_age), ] 
# Create a list to store all results
all_results <- list()

# Loop through different numbers of PCs (3 to 10)
for(num_pcs in 3:10) {
  # Create PC dataframe
  pca_temp <- pca(df[, 21:ncol(df), ])
  pc_df <- data.frame(PC1 = rep(0,nrow(df)))
  for (i in 1:num_pcs) {
    pc_df[, paste0("PC", i)] <- pca_temp$res$cal$scores[, i]
  }
  pc_df <- cbind(pc_df,df)
  
  # Create formula strings dynamically based on num_pcs
  lm_formula_terms <- paste0("PC", 1:num_pcs, collapse = " + ")
  gam_formula_terms <- paste0("s(PC", 1:num_pcs, ",k = 4)", collapse = " + ")
  
  # Create global models
  global_lm <- lm(as.formula(paste("read_age ~", lm_formula_terms)), data = pc_df)
  global_gam <- gam(as.formula(paste("read_age ~", gam_formula_terms)), data = pc_df)
  
  # Dredge to find top 5 models
  options(na.action = "na.fail")
  dredge_lm <- dredge(global_lm)
  top5_lm <- get.models((dredge_lm), subset = 1:5)
  dredge_gam <- dredge(global_gam)
  top5_gam <- get.models(dredge_gam, subset = 1:5)
  
  terms_lm <- list()
  terms_gam <- list()
  for(i in 1:5){
    terms_lm[[i]] <- top5_lm[[i]]$terms
    terms_gam[[i]] <- top5_gam[[i]]$formula
  }
  
  # 10 fold CV split
  set.seed(6)
  splits <- caret::createFolds(df$read_age, k = 10, list = TRUE, returnTrain = FALSE)
  
  # Create calibration and test sets
  cal <- list()
  test <- list()
  for (i in 1:10) {
    pc.mod <- preProcess(df[-splits[[i]], -c(1:20)], method = c("pca","center"), pcaComp = num_pcs)
    pc.cal <- predict(pc.mod, df[-splits[[i]], -c(1:20)])
    pc.cal <- cbind(pc.cal, df[-splits[[i]], ])
    cal[[i]] <- pc.cal
    
    pc.test <- predict(pc.mod, df[splits[[i]], -c(1:20)])
    pc.test <- cbind(pc.test, df[splits[[i]], ])
    test[[i]] <- pc.test
  }
  
  # LM - top 5 models
  mods.lm <- replicate(10, list())
  r2_lm <- list()
  rmse_lm <- list()
  for (i in 1:10) {
    calibrate <- cal[[i]]
    testing <- test[[i]]
    r2_temp <- rep(0, 5)
    rmse_temp <- rep(0, 5)
    for (j in 1:5) {
      mod <- lm(data = calibrate, terms_lm[[j]])
      preds <- predict(mod, newdata = testing)
      rmse_temp[j] <- caret::RMSE(pred = preds, obs = testing[, "read_age"])
      RSS <- sum((testing$read_age - preds)^2)
      TSS <- sum((testing$read_age - mean(testing$read_age))^2)
      r2_temp[j] <- 1 - (RSS / TSS)
      mods.lm[[i]][[j]] <- mod
    }
    r2_lm[[i]] <- data.frame(Model = paste0("Linear ", 1:5), r2 = r2_temp)
    rmse_lm[[i]] <- data.frame(Model = paste0("Linear ", 1:5), rmse = rmse_temp)
  }
  
  # GAM - top 5 models
  mods.gam <- replicate(10, list())
  r2_gam <- list()
  rmse_gam <- list()
  for (i in 1:10) {
    calibrate <- cal[[i]]
    testing <- test[[i]]
    r2_temp <- rep(0, 5)
    rmse_temp <- rep(0, 5)
    for (j in 1:5) {
      mod <- gam(data = calibrate, terms_gam[[j]])
      preds <- predict(mod, newdata = testing)
      rmse_temp[j] <- caret::RMSE(pred = preds, obs = testing[, "read_age"])
      RSS <- sum((testing$read_age - preds)^2)
      TSS <- sum((testing$read_age - mean(testing$read_age))^2)
      r2_temp[j] <- 1 - (RSS / TSS)
      mods.gam[[i]][[j]] <- mod
    }
    r2_gam[[i]] <- data.frame(Model = paste0("GAM ", 1:5), r2 = r2_temp)
    rmse_gam[[i]] <- data.frame(Model = paste0("GAM ", 1:5), rmse = rmse_temp)
  }
  
  # Modify the results creation part within the main loop:
  
  # Calculate final results
  r2_lm <- sapply(r2_lm, "[[", "r2")
  r2_lm <- rowMeans(r2_lm)
  rmse_lm <- sapply(rmse_lm, "[[", "rmse")
  rmse_lm <- rowMeans(rmse_lm)
  
  # Create lm_result with formulas
  lm_result <- data.frame(
    Model = paste0("Linear ", 1:5),
    Mean_R2 = r2_lm,
    Mean_RMSE = rmse_lm,
    Formula = sapply(top5_lm, function(x) Reduce(paste, deparse(formula(x))))  # Extract formula
  )
  
  r2_gam <- sapply(r2_gam, "[[", "r2")
  r2_gam <- rowMeans(r2_gam)
  rmse_gam <- sapply(rmse_gam, "[[", "rmse")
  rmse_gam <- rowMeans(rmse_gam)
  
  # Create gam_result with formulas
  gam_result <- data.frame(
    Model = paste0("GAM ", 1:5),
    Mean_R2 = r2_gam,
    Mean_RMSE = rmse_gam,
    Formula = sapply(top5_gam, function(x) Reduce(paste, deparse(formula(x))))  # Extract formula
  )
  
  # Combine results and add number of PCs
  results <- rbind(lm_result, gam_result)
  results$Num_PCs <- num_pcs
  
  # Store results for this iteration
  all_results[[paste0("PCs_", num_pcs)]] <- results
}

# Combine all results into one dataframe
final_results <- do.call(rbind, all_results)
rownames(final_results) <- NULL
```



## Functions for above code to run all modelling with given data frame are in this section

```{r include=FALSE}
run_models <- function(mydf){
df <- {{mydf}}
df <- df[complete.cases(df$read_age), ] 
pca_temp <- pca(df[, 21:ncol(df), ])
pc_df <- data.frame(PC1 = rep(0,nrow(df)))
for (i in 1:10) {
  pc_df[, paste0("PC", i)] <- pca_temp$res$cal$scores[, i]
  rm(i)
}
pc_df <- cbind(pc_df,df) 
global_lm <- lm(data = pc_df, read_age ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10)
global_gam <- gam(data = pc_df, read_age ~ s(PC1,k=4) + s(PC2,k=4) + s(PC3,k=4) + s(PC4,k=4) + s(PC5,k=4) + s(PC6,k=4)) # adding too many PC's makes GAM have horrible fit and R2

# dredge to find top 5 models
options(na.action = "na.fail")
dredge_lm <- dredge(global_lm)
top5_lm <- get.models(dredge_lm, subset = 1:5)

# get.models was not working for gam in a function format so had to adapt this insane code to extract the top models....
dredge_gam <- dredge(global_gam)
top5_gam_temp <- dredge_gam[1:5,] 
reconstruct_formula <- function(model_row) {
  terms_used <- names(model_row)[!is.na(model_row)]   # Extract the terms used in the model
  terms_used <- terms_used[!terms_used %in% c("(Intercept)", "df", "logLik", "AICc", "delta", "weight")]   # Remove non-predictor columns (e.g., AIC, delta, weight)
  as.formula(paste("read_age ~", paste(terms_used, collapse = " + ")))   # Construct the formula
}
top5_gam <- lapply(1:5, function(i) {reconstruct_formula(top5_gam_temp[i, ])})
rm(top5_gam_temp, reconstruct_formula)

# create lists for top 5 models of lm and gam
terms_lm <- list()
terms_gam <- list()
for(i in 1:5){
  terms_lm[[i]] <- top5_lm[[i]]$terms
  terms_gam[[i]] <- top5_gam[[i]]
  rm(i)
}
rm(global_gam, global_lm, top5_gam, top5_lm, pc_df, pca_temp, dredge_gam,dredge_lm)

# 10 fold CV split - create folds
set.seed(6)
splits <- caret::createFolds(df$read_age, k = 10, list = TRUE, returnTrain = FALSE)
# extract PC's for each calibration set, create test sets with ages and spectra
cal <- list()
test <- list()
for (i in 1:10) {
  # calibration set and PC's
  pc.mod <- preProcess(df[-splits[[i]], -c(1:20)], method = c("pca","center"), pcaComp = 10)
  pc.cal <- predict(pc.mod, df[-splits[[i]], -c(1:20)])
  pc.cal <- cbind(pc.cal, df[-splits[[i]], ])
  cal[[i]] <- pc.cal
  rm(pc.cal)
  # test sets
  pc.test <- predict(pc.mod, df[splits[[i]], -c(1:20)])
  pc.test <- cbind(pc.test, df[splits[[i]], ])
  test[[i]] <- pc.test
  rm(pc.test, pc.mod, i)
}

mods.lm <- replicate(10, list())
r2_lm <- list()
rmse_lm <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  r2_temp <- rep(0, 5)
  rmse_temp <- rep(0, 5)
  for (j in 1:5) {
    mod <- lm(data = calibrate, terms_lm[[j]])
    preds <- predict(mod, newdata = testing)
    rmse_temp[j] <- caret::RMSE(pred = preds, obs = testing[, "read_age"])
    RSS <- sum((testing$read_age - preds)^2)
    TSS <- sum((testing$read_age - mean(testing$read_age))^2)
    r2_temp[j] <- 1 - (RSS / TSS)
    mods.lm[[i]][[j]] <- mod
    rm(RSS, TSS, preds)
  }
  r2_lm[[i]] <- data.frame(Model = paste0("Linear ", 1:5), r2 = r2_temp)
  rmse_lm[[i]] <- data.frame(Model = paste0("Linear ", 1:5), rmse = rmse_temp)
  rm(mod, i, j, r2_temp, rmse_temp, calibrate, testing)
}
# Unlist the r2 & rmse values and calc means for 10 splits, combine into dataframe
r2_lm <- sapply(r2_lm, "[[", "r2")
r2_lm <- rowMeans(r2_lm)
rmse_lm <- sapply(rmse_lm, "[[", "rmse")
rmse_lm <- rowMeans(rmse_lm)
(lm_result <- data.frame(
  Model = paste0("Linear ", 1:5),
  Mean_R2 = r2_lm,
  Mean_RMSE = rmse_lm
))
rm(r2_lm, rmse_lm)

mods.gam <- replicate(10, list())
r2_gam <- list()
rmse_gam <- list()
for (i in 1:10) {
  calibrate <- cal[[i]]
  testing <- test[[i]]
  r2_temp <- rep(0, 5)
  rmse_temp <- rep(0, 5)
  for (j in 1:5) {
    mod <- gam(data = calibrate, terms_gam[[j]])
    preds <- predict(mod, newdata = testing)
    rmse_temp[j] <- caret::RMSE(pred = preds, obs = testing[, "read_age"])
    RSS <- sum((testing$read_age - preds)^2)
    TSS <- sum((testing$read_age - mean(testing$read_age))^2)
    r2_temp[j] <- 1 - (RSS / TSS)
    mods.gam[[i]][[j]] <- mod
    rm(RSS, TSS, preds)
  }
  r2_gam[[i]] <- data.frame(Model = paste0("GAM ", 1:5), r2 = r2_temp)
  rmse_gam[[i]] <- data.frame(Model = paste0("GAM ", 1:5), rmse = rmse_temp)
  rm(j, i, testing, calibrate, mod, r2_temp, rmse_temp)
}
r2_gam <- sapply(r2_gam, "[[", "r2")
r2_gam <- rowMeans(r2_gam)
rmse_gam <- sapply(rmse_gam, "[[", "rmse")
rmse_gam <- rowMeans(rmse_gam)
gam_result <- data.frame(
  Model = paste0("GAM ", 1:5),
  Mean_R2 = r2_gam,
  Mean_RMSE = rmse_gam
)
(results <- rbind(lm_result,gam_result))
rm(r2_gam, rmse_gam, lm_result, gam_result)

mods.pls <- list()
mods.vip <- list()
r2.pls <- list()
rmse.pls <- list()
for (i in 1:10) {
  calibrate <- df[-splits[[i]], ]
  testing <- df[splits[[i]], ]
  mod <- pls(calibrate[, 31:ncol(calibrate)], calibrate[, "read_age"],
             scale = F, center = T, cv = 1, #ncomp.selcrit = "wold", removing for now, seems too conservative with number of selected components
             info = "Age Prediction Model",
             x.test = testing[, 31:ncol(testing)],
             y.test = testing[, "read_age"]
  )
  ncomp <- mod$ncomp.selected
  rmse.pls$pls.test[i] <- mod$testres$rmse[[ncomp]] # extract rmse
  r2.pls$pls.test[i] <- mod$testres$r2[[ncomp]] # extract r2
  
  # VIP filter of wavenumbers
  mods.pls[[i]] <- mod
  mods.pls[[1]]$ncomp.selected
  vip <- as.data.frame(vipscores(mod))
  mod <- pls(calibrate[, 31:ncol(calibrate)], calibrate[, "read_age"],
             # ncomp.selcrit = "wold", 
             scale = F, center = T, cv = 1,
             info = "Age Prediction Model",
             x.test = testing[, 31:ncol(testing)],
             y.test = testing[, "read_age"],
             exclcols = vip$V1 < 0.5
  )
  ncomp <- mod$ncomp.selected
  r2.pls$vip.test[i] <- mod$testres$r2[[ncomp]] # extract r2
  mods.vip[[i]] <- mod
  rmse.pls$vip.test[i] <- mod$testres$rmse[[ncomp]] # extract rmse
  rm(calibrate, mod, ncomp, testing, i, vip)
}
(results <- rbind(results, 
                  c("PLS", mean(r2.pls$pls.test), mean(rmse.pls$pls.test)),
                  c("VIP", mean(r2.pls$vip.test), mean(rmse.pls$vip.test))
))
rm(rmse.pls, r2.pls)
mods.lm <<- mods.lm
mods.gam <<- mods.gam
mods.pls <<- mods.pls
mods.vip <<- mods.vip
return(results)
}


get.my.models <- function() {
  model.list <- list(lm = list(), gam = list(), pls = list(), vip = list())
  model.list$lm <- mods.lm
  model.list$gam <- mods.gam
  model.list$pls <- mods.pls
  model.list$vip <- mods.vip
  rm(mods.lm, mods.gam, mods.pls, mods.vip, pos = .GlobalEnv)
  return(model.list)
}

```

### Including all wavenumbers, no outliers removed

```{r}
# ALL waves
df <- readRDS("RDS_dataframes/LPW_scan_avg_proc.RDS")
results_allwaves <- run_models(df)
mods_allwaves <- get.my.models()
saveRDS(results_allwaves, "results_allwaves.RDS")
saveRDS(mods_allwaves, "mods_allwaves.RDS")
```

### Excluding wavenumbers > 7500, no outliers removed

```{r}
# cut off >7500 wavenumber
df <- readRDS("RDS_dataframes/LPW_scan_avg_proc_filter.RDS")
results_filtered <- run_models(df)
mods_filtered <- get.my.models()
saveRDS(results_filtered, "results_filtered.RDS")
saveRDS(mods_filtered, "mods_filtered.RDS")
```

## All wavenumbers, remove specimen #77 (very large)

```{r}
# remove specimen 77, all waves
df <- readRDS("RDS_dataframes/LPW_scan_avg_proc.RDS")
df <- df %>% filter(specimen != 77)
results_allwaves_no77 <- run_models(df)
mods_allwaves_no77 <- get.my.models()
saveRDS(results_allwaves_no77, "results_allwaves_no77.RDS")
saveRDS(mods_allwaves_no77, "mods_allwaves_no77.RDS")
```

